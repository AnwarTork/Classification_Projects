{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "URp1dPJNaG4N"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Abjad_books.csv')"
      ],
      "metadata": {
        "id": "06Bl8gwTa9od"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "kVboR5hlbCoH",
        "outputId": "0514f0da-fbd6-4502-fe0c-c961df40d752"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        BookBadge_Title                Author  Rating  \\\n",
              "0              ماجدولين  مصطفى لطفي المنفلوطي     4.4   \n",
              "1            هكذا خُلقت        محمد حسين هيكل     4.2   \n",
              "2  قواعد العشق الأربعون           إليف  شافاق     4.3   \n",
              "3    في قلبي أنثى عبرية             خولة حمدي     4.5   \n",
              "4      الأرواح المتمردة      جبران خليل جبران     4.3   \n",
              "\n",
              "                                         Description  Raters  Reviews  \\\n",
              "0  لا نعرف عن الحُب غير وجهه الأليف الذي نُحِب، ل...    4057     4313   \n",
              "1  روايةٌ واقعيةٌ تركَتْها بين يدَيِ المؤلف امرأة...    2701     2944   \n",
              "2  بلغت بطلة الرواية، إيلاّ الزوجة التعيسة، سنّ ا...    2643     2777   \n",
              "3  في قلب حارة اليهود في الجنوب التونسي تتشابك ال...    3405     3518   \n",
              "4  «الأرواح المتمردة» هو كتاب صدر لأول مرة في مدي...    2478     2635   \n",
              "\n",
              "   Readers                                               Link  \n",
              "0    23055  https://www.abjjad.com/book/15445318/%D9%85%D8...  \n",
              "1    14769  https://www.abjjad.com/book/2019491840/%D9%87%...  \n",
              "2     8242  https://www.abjjad.com/book/2138898432/%D9%82%...  \n",
              "3    10091  https://www.abjjad.com/book/2073100288/%D9%81%...  \n",
              "4     9857  https://www.abjjad.com/book/15445260/%D8%A7%D9...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83738bd2-d490-42eb-b9f5-16fce5d7280c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>BookBadge_Title</th>\n",
              "      <th>Author</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Description</th>\n",
              "      <th>Raters</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Readers</th>\n",
              "      <th>Link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ماجدولين</td>\n",
              "      <td>مصطفى لطفي المنفلوطي</td>\n",
              "      <td>4.4</td>\n",
              "      <td>لا نعرف عن الحُب غير وجهه الأليف الذي نُحِب، ل...</td>\n",
              "      <td>4057</td>\n",
              "      <td>4313</td>\n",
              "      <td>23055</td>\n",
              "      <td>https://www.abjjad.com/book/15445318/%D9%85%D8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>هكذا خُلقت</td>\n",
              "      <td>محمد حسين هيكل</td>\n",
              "      <td>4.2</td>\n",
              "      <td>روايةٌ واقعيةٌ تركَتْها بين يدَيِ المؤلف امرأة...</td>\n",
              "      <td>2701</td>\n",
              "      <td>2944</td>\n",
              "      <td>14769</td>\n",
              "      <td>https://www.abjjad.com/book/2019491840/%D9%87%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قواعد العشق الأربعون</td>\n",
              "      <td>إليف  شافاق</td>\n",
              "      <td>4.3</td>\n",
              "      <td>بلغت بطلة الرواية، إيلاّ الزوجة التعيسة، سنّ ا...</td>\n",
              "      <td>2643</td>\n",
              "      <td>2777</td>\n",
              "      <td>8242</td>\n",
              "      <td>https://www.abjjad.com/book/2138898432/%D9%82%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>في قلبي أنثى عبرية</td>\n",
              "      <td>خولة حمدي</td>\n",
              "      <td>4.5</td>\n",
              "      <td>في قلب حارة اليهود في الجنوب التونسي تتشابك ال...</td>\n",
              "      <td>3405</td>\n",
              "      <td>3518</td>\n",
              "      <td>10091</td>\n",
              "      <td>https://www.abjjad.com/book/2073100288/%D9%81%...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الأرواح المتمردة</td>\n",
              "      <td>جبران خليل جبران</td>\n",
              "      <td>4.3</td>\n",
              "      <td>«الأرواح المتمردة» هو كتاب صدر لأول مرة في مدي...</td>\n",
              "      <td>2478</td>\n",
              "      <td>2635</td>\n",
              "      <td>9857</td>\n",
              "      <td>https://www.abjjad.com/book/15445260/%D8%A7%D9...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83738bd2-d490-42eb-b9f5-16fce5d7280c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83738bd2-d490-42eb-b9f5-16fce5d7280c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83738bd2-d490-42eb-b9f5-16fce5d7280c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# نريد تدريب نموذج يقرأ وصف كتاب باللغة العربية، ويقوم بتصنيفه إلى تقييم منخفض أو متوسط أو عالي، بالاعتماد على المواضيع الكامنة داخل النصوص.\n",
        "\n",
        "# نريد بناء نظام يستطيع أن:\n",
        "\n",
        "# يقرأ أوصاف الكتب (وصف نصي).\n",
        "\n",
        "# يستخرج منها المواضيع باستخدام LDA.\n",
        "\n",
        "# يستخدم تلك المواضيع لتصنيف الكتاب حسب تقييمه إلى:\n",
        "\n",
        "# 🟥 منخفض (أقل من 3.5)\n",
        "\n",
        "# 🟨 متوسط (من 3.5 إلى أقل من 4.25)\n",
        "\n",
        "# 🟩 عالي (4.25 أو أكثر)\n",
        "\n"
      ],
      "metadata": {
        "id": "6K-nXWCLe9oM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gngcXxUybDxW",
        "outputId": "1393fd06-1cb3-4a53-d515-dc1e1a0f33ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(440, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تحويل التقييم إلى فئة تصنيفية\n",
        "# لأن Rating رقمي (مثل 4.4 أو 3.2)، نحوله إلى فئات:\n",
        "\n",
        "def classify_rating(r):\n",
        "    if r < 3.5:\n",
        "        return \"منخفض\"\n",
        "    elif r < 4.25:\n",
        "        return \"متوسط\"\n",
        "    else:\n",
        "        return \"عالي\"\n",
        "\n",
        "df['RatingClass'] = df['Rating'].apply(classify_rating)\n"
      ],
      "metadata": {
        "id": "zIJA1qgJfRWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pandas nltk scikit-learn gensim pyarabic"
      ],
      "metadata": {
        "id": "sn8Q5vmXbEvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "descriptions = df['Description'].dropna().tolist()"
      ],
      "metadata": {
        "id": "bdvieMLAbVWW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from pyarabic.araby import strip_tashkeel, strip_diacritics, normalize_hamza\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "arabic_stopwords = set(stopwords.words(\"arabic\"))\n",
        "\n",
        "def preprocess(text):\n",
        "    # إزالة التشكيل والنصوص غير العربية\n",
        "    text = strip_diacritics(strip_tashkeel(normalize_hamza(text)))\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)  # إزالة الرموز غير العربية\n",
        "    tokens = text.split()\n",
        "    tokens = [t for t in tokens if t not in arabic_stopwords and len(t) > 2]\n",
        "    return tokens\n",
        "\n",
        "processed_descriptions = [preprocess(desc) for desc in descriptions]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyxyTAu1boVZ",
        "outputId": "535570d6-e3a6-45e2-c3cd-646a8cd3c6e0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dictionary: تبني قاموس من الكلمات.\n",
        "\n",
        "# Corpus: تحويل النصوص إلى قوائم bow (Bag-of-Words).\n",
        "\n",
        "# LDA: تستخرج المواضيع الكامنة."
      ],
      "metadata": {
        "id": "wYWQ_X0hflzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  إنشاء القاموس والكوربوس:\n",
        "#  يقوم بإنشاء قاموس (dictionary) يحتوي على جميع الكلمات الفريدة الموجودة في قائمة texts.\n",
        "\n",
        "# كل كلمة تأخذ معرّف رقمي (id).\n",
        "\n",
        "# مثال:\n",
        "# إذا كان لدينا texts = [[\"حب\", \"موت\"], [\"حب\", \"أمل\"]]\n",
        "# فإن dictionary.token2id يكون مثل: {\"حب\": 0, \"موت\": 1, \"أمل\": 2}\n",
        "\n",
        "# corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "# يحوّل كل نص في texts إلى تمثيل بطريقة Bag of Words (BoW).\n",
        "\n",
        "# كل نص يصبح قائمة من tuples (word_id, count).\n",
        "\n",
        "# 🧠 مثال توضيحي:\n",
        "# إذا كان text = [\"حب\", \"أمل\"]، يصبح:\n",
        "# [(0, 1), (2, 1)]  # 0 = \"حب\", 2 = \"أمل\"\n",
        "\n",
        "#  تدريب نموذج LDA:\n",
        "#  هذا السطر يقوم بتدريب نموذج LDA (Latent Dirichlet Allocation).\n",
        "\n",
        "# الهدف هو تعلم عدد 5 مواضيع (يمكنك تغييره).\n",
        "\n",
        "# كل موضوع هو توزيع احتمالي على الكلمات، وكل نص هو توزيع على المواضيع.\n",
        "\n",
        "# 🧠 مثلاً:\n",
        "\n",
        "# موضوع 1 ← {\"حب\": 0.3, \"موت\": 0.2, \"حرب\": 0.1, ...}\n",
        "\n",
        "# موضوع 2 ← {\"إيمان\": 0.4, \"روح\": 0.3, ...}\n",
        "# دالة تحويل وصف كتاب إلى توزيع مواضيع:\n",
        "# def get_topic_vector(bow):\n",
        "#     topics = lda.get_document_topics(bow, minimum_probability=0)\n",
        "#     return [prob for _, prob in sorted(topics, key=lambda x: x[0])]\n",
        "\n",
        "# شرح:\n",
        "\n",
        "# تأخذ وصف كتاب تم تحويله إلى BoW.\n",
        "\n",
        "# تستخرج منه توزيعًا احتماليًا على المواضيع.\n",
        "\n",
        "# تُرجع قائمة بطول num_topics، كل عنصر فيها يمثل احتمالية انتماء النص لكل موضوع.\n",
        "\n",
        "# 🧠 مثال:\n",
        "# [(0, 0.05), (1, 0.70), (2, 0.10), (3, 0.10), (4, 0.05)]\n",
        "# ⇒ [0.05, 0.70, 0.10, 0.10, 0.05]\n",
        "\n",
        "# تطبيق الدالة على كل النصوص للحصول على X:\n",
        "# X = np.array([get_topic_vector(bow) for bow in corpus])\n",
        "\n",
        "# لكل نص في corpus، يتم حساب توزيع المواضيع.\n",
        "\n",
        "# النتيجة X هي مصفوفة (عدد الكتب × عدد المواضيع).\n",
        "\n",
        "# هذه المصفوفة يمكن استخدامها كـ Features في أي نموذج تصنيف.\n",
        "\n",
        "# 🧠 مثال تخيلي (5 مواضيع × 3 كتب):\n",
        "# X =\n",
        "# [[0.05, 0.70, 0.10, 0.10, 0.05],\n",
        "#  [0.60, 0.10, 0.05, 0.15, 0.10],\n",
        "#  [0.20, 0.20, 0.20, 0.20, 0.20]]\n",
        "\n",
        "#  ماذا نحتاج هذه الخطوة؟\n",
        "# لأننا نحتاج أن نحول نصوص غير منظمة (Unstructured) إلى بيانات عددية منظمة يمكن لنموذج التعلم الآلي (مثل XGBoost) فهمها."
      ],
      "metadata": {
        "id": "aNs0XXY0hGv-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#تحويل الكلمات إلى نموذج عددي (Bag of Words أو TF-IDF)\n",
        "from gensim import corpora\n",
        "\n",
        "# إنشاء القاموس\n",
        "dictionary = corpora.Dictionary(processed_descriptions)\n",
        "\n",
        "# تحويل النصوص إلى تمثيل عددي\n",
        "corpus = [dictionary.doc2bow(text) for text in processed_descriptions]"
      ],
      "metadata": {
        "id": "5IyqWS9Vbsnq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# تطبيق LDA - Latent Dirichlet Allocation\n",
        "from gensim.models import LdaModel\n",
        "\n",
        "lda_model = LdaModel(corpus=corpus,\n",
        "                     id2word=dictionary,\n",
        "                     num_topics=5,  # عدد المواضيع المطلوب استخلاصها\n",
        "                     random_state=42,\n",
        "                     passes=10)\n",
        "\n",
        "# طباعة المواضيع المستخلصة\n",
        "topics = lda_model.print_topics(num_words=5)\n",
        "for idx, topic in topics:\n",
        "    print(f\"🟢 موضوع {idx + 1}: {topic}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMJbkk4Wb1Uh",
        "outputId": "db89511f-d0d8-43e3-eb35-4db08de25b03"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🟢 موضوع 1: 0.009*\"ءلى\" + 0.008*\"الكتاب\" + 0.007*\"كتاب\" + 0.005*\"النفس\" + 0.005*\"ءحد\"\n",
            "🟢 موضوع 2: 0.014*\"الكتاب\" + 0.009*\"ءلى\" + 0.004*\"العالم\" + 0.003*\"ءكثر\" + 0.003*\"الكاتب\"\n",
            "🟢 موضوع 3: 0.009*\"ءلى\" + 0.009*\"الكتاب\" + 0.006*\"لكل\" + 0.006*\"كتاب\" + 0.006*\"محمد\"\n",
            "🟢 موضوع 4: 0.014*\"الكتاب\" + 0.007*\"ءلى\" + 0.004*\"وهي\" + 0.003*\"العالم\" + 0.003*\"يكون\"\n",
            "🟢 موضوع 5: 0.007*\"ءلى\" + 0.006*\"الكتاب\" + 0.005*\"كتاب\" + 0.004*\"النفس\" + 0.004*\"كانت\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyLDAvis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_v4oD-Yob9jM",
        "outputId": "f26e3c05-67ae-464d-fe46-0ebe7965e352"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.13.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.11.0)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (4.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim->pyLDAvis) (7.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim->pyLDAvis) (1.17.2)\n",
            "Downloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, pyLDAvis\n",
            "Successfully installed funcy-2.0 pyLDAvis-3.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "vis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 881
        },
        "id": "SFMMBOt3cFi8",
        "outputId": "1ede2157-cd19-4641-d845-c01bdab33b35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "0      0.201109 -0.032197       1        1  21.964788\n",
              "2      0.024038 -0.041717       2        1  20.542464\n",
              "3     -0.140348 -0.102954       3        1  20.093022\n",
              "1     -0.044471 -0.038824       4        1  19.049536\n",
              "4     -0.040327  0.215692       5        1  18.350190, topic_info=        Term       Freq      Total Category  logprob  loglift\n",
              "516    النفس  26.000000  26.000000  Default  30.0000  30.0000\n",
              "446    ءحداث  13.000000  13.000000  Default  29.0000  29.0000\n",
              "1510     لكل  20.000000  20.000000  Default  28.0000  28.0000\n",
              "1157    رحلة   8.000000   8.000000  Default  27.0000  27.0000\n",
              "549     كانت  18.000000  18.000000  Default  26.0000  26.0000\n",
              "...      ...        ...        ...      ...      ...      ...\n",
              "1020  الكثير   4.662110  11.404466   Topic5  -6.0822   0.8010\n",
              "580    تاريخ   4.655135  11.408932   Topic5  -6.0837   0.7991\n",
              "831    الفرد   4.654054   6.792109   Topic5  -6.0840   1.3175\n",
              "846    يحاول   4.653835   6.792106   Topic5  -6.0840   1.3175\n",
              "836      شيء   4.648913   9.852627   Topic5  -6.0851   0.9444\n",
              "\n",
              "[279 rows x 6 columns], token_table=      Topic      Freq      Term\n",
              "term                           \n",
              "829       5  0.950133  ءءليتها،\n",
              "244       1  0.570631       ءحد\n",
              "244       2  0.103751       ءحد\n",
              "244       3  0.103751       ءحد\n",
              "244       4  0.259378       ءحد\n",
              "...     ...       ...       ...\n",
              "1273      4  0.153807      يكون\n",
              "871       1  0.690249      يمكن\n",
              "871       2  0.172562      يمكن\n",
              "871       5  0.172562      يمكن\n",
              "338       4  0.791328      ينزل\n",
              "\n",
              "[359 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 3, 4, 2, 5])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el26351404108926205601942919776\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el26351404108926205601942919776_data = {\"mdsDat\": {\"x\": [0.20110884710482527, 0.024037570939481893, -0.14034839280417943, -0.04447129140306777, -0.04032673383705997], \"y\": [-0.0321967864924234, -0.041717219250078916, -0.10295410077582184, -0.03882433911791586, 0.21569244563624002], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [21.964787789144857, 20.542464236183545, 20.093022134156282, 19.049536209797026, 18.35018963071829]}, \"tinfo\": {\"Term\": [\"\\u0627\\u0644\\u0646\\u0641\\u0633\", \"\\u0621\\u062d\\u062f\\u0627\\u062b\", \"\\u0644\\u0643\\u0644\", \"\\u0631\\u062d\\u0644\\u0629\", \"\\u0643\\u0627\\u0646\\u062a\", \"\\u0645\\u062d\\u0645\\u062f\", \"\\u062f\\u0631\\u062c\\u0629\", \"\\u0627\\u0644\\u0646\\u062c\\u0627\\u062d\", \"\\u0627\\u0644\\u0621\\u0645\\u0627\\u0645\", \"\\u0643\\u062a\\u0628\", \"\\u0627\\u0644\\u0639\\u062b\\u0645\\u0627\\u0646\\u064a\\u0629\", \"\\u062d\\u064a\\u0627\\u062a\\u0647\", \"\\u0621\\u0647\\u0645\\u064a\\u0629\", \"\\u0641\\u0644\\u0633\\u0637\\u064a\\u0646\", \"\\u0639\\u0644\\u064a\\u0647\\u0627\", \"\\u0627\\u0644\\u062a\\u0639\\u0627\\u0645\\u0644\", \"\\u0627\\u0644\\u0621\\u0644\\u064a\\u0627\\u0630\\u0629\", \"\\u0628\\u064a\\u0627\\u0646\\u0627\\u062a\", \"\\u0641\\u0642\\u062f\", \"\\u0639\\u0645\\u0631\", \"\\u0627\\u0644\\u062d\\u0628\", \"\\u0645\\u0648\\u0636\\u0648\\u0639\\u0627\\u062a\", \"\\u0627\\u0644\\u0621\\u0646\\u0633\\u0627\\u0646\\u060c\", \"\\u0627\\u0644\\u0644\\u0647\", \"\\u062f\\u0631\\u0627\\u0633\\u0629\", \"\\u0627\\u0644\\u0621\\u0634\\u0627\\u0639\\u0629\", \"\\u0648\\u0627\\u0644\\u062f\\u0639\\u0627\\u064a\\u0629\", \"\\u0621\\u062d\\u062f\", \"\\u0627\\u0644\\u0642\\u0627\\u0631\\u0621\", \"\\u0634\\u062e\\u0635\", \"\\u0627\\u0644\\u0642\\u0631\\u0627\\u0621\\u0629\", \"\\u0639\\u064a\\u062f\", \"\\u062e\\u0644\\u0648\\u062f\", \"\\u0627\\u0644\\u0630\\u0643\\u0631\", \"\\u064a\\u0632\\u062e\\u0631\", \"\\u0627\\u0644\\u0631\\u0627\\u0634\\u062f\", \"\\u0627\\u0644\\u0643\\u0628\\u0631\\u0649\", \"\\u0628\\u0631\\u062c\\u0627\\u0644\", \"\\u0627\\u0644\\u0646\\u0628\\u064a\\u060c\", \"\\u0644\\u0644\\u0646\\u0627\\u0633\\u060c\", \"\\u0627\\u0644\\u0639\\u0627\\u062f\\u0644\\u060c\", \"\\u0627\\u0644\\u062e\\u0637\\u0627\\u0628\", \"\\u0635\\u062d\\u0627\\u0628\\u0629\", \"\\u0641\\u062d\\u0642\", \"\\u062d\\u0648\\u0627\\u062f\\u062b\\u0647\", \"\\u064a\\u0634\\u0639\", \"\\u0646\\u0648\\u0631\", \"\\u0639\\u0638\\u0627\\u0645\", \"\\u062f\\u062e\\u0648\\u0644\", \"\\u0633\\u0637\\u0631\\u0648\\u0627\", \"\\u0647\\u0621\\u0644\\u0627\\u0621\", \"\\u0635\\u0644\\u0627\\u062d\\u0647\\u0645\", \"\\u0648\\u0646\\u0641\\u0639\\u0647\\u0645\", \"\\u0628\\u062d\\u0631\\u0648\\u0641\", \"\\u0648\\u0627\\u0644\\u062e\\u0644\\u064a\\u0641\\u0629\", \"\\u0627\\u0644\\u0621\\u0633\\u0641\\u0627\\u0631\", \"\\u0641\\u0628\\u0639\\u062f\", \"\\u0627\\u0644\\u0634\\u0631\\u0639\\u064a\\u0629\", \"\\u0648\\u0627\\u0644\\u062a\\u0646\\u0648\\u064a\\u0631\", \"\\u0631\\u0648\\u0633\\u0648\", \"\\u0627\\u0644\\u0621\\u0645\\u0627\\u0645\", \"\\u0641\\u0642\\u062f\", \"\\u0639\\u0645\\u0631\", \"\\u064a\\u0645\\u0643\\u0646\", \"\\u0621\\u062d\\u062f\", \"\\u0627\\u0644\\u0646\\u0641\\u0633\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0621\\u0644\\u0649\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u0639\\u0635\\u0631\", \"\\u0627\\u0644\\u0627\\u062c\\u062a\\u0645\\u0627\\u0639\\u064a\", \"\\u0645\\u0635\\u0631\", \"\\u064a\\u0639\\u062f\", \"\\u0639\\u0627\\u0644\\u0645\", \"\\u0627\\u0644\\u0621\\u0633\\u0644\\u0627\\u0645\\u064a\", \"\\u0643\\u0628\\u0627\\u0631\", \"\\u062f\\u0631\\u0627\\u0633\\u0629\", \"\\u0627\\u0644\\u0621\\u0634\\u0627\\u0639\\u0629\", \"\\u0648\\u0627\\u0644\\u062f\\u0639\\u0627\\u064a\\u0629\", \"\\u0648\\u0646\\u0634\\u0621\\u0629\", \"\\u0627\\u0644\\u0637\\u0648\\u0627\\u0644\\u060c\", \"\\u062a\\u0641\\u0627\\u0635\\u064a\", \"\\u0645\\u0639\\u0632\\u0632\\u0629\", \"\\u0627\\u0644\\u0645\\u062d\\u0645\\u062f\\u064a\\u0629\\u061b\", \"\\u0628\\u062a\\u0641\\u0627\\u0635\\u064a\\u0644\", \"\\u0645\\u064a\\u0644\\u0627\\u062f\", \"\\u0627\\u062d\\u062a\\u0641\\u0649\", \"\\u0627\\u0644\\u0645\\u062c\\u0644\\u062f\\u0627\\u062a\", \"\\u0628\\u0627\\u0644\\u0633\\u064a\\u0631\\u0629\", \"\\u0628\\u0627\\u0644\\u0621\\u0633\\u0627\\u0646\\u064a\\u062f\", \"\\u0643\\u062b\\u064a\\u0631\\u0629\", \"\\u0621\\u0633\\u0647\\u0628\\u062a\", \"\\u0627\\u0644\\u0646\\u0628\\u064a\\u061b\", \"\\u0648\\u0645\\u063a\\u0631\\u0642\\u0629\", \"\\u0627\\u0644\\u0648\\u0641\\u0627\\u0629\", \"\\u0627\\u0644\\u0645\\u0648\\u0644\\u062f\", \"\\u0641\\u0621\\u0641\\u0631\\u062f\", \"\\u0627\\u0644\\u063a\\u0631\\u0628\\u064a\\u0629\", \"\\u0627\\u0644\\u0621\\u0639\\u0644\\u0627\\u0645\", \"\\u0648\\u0633\\u0644\\u0645\\u060c\", \"\\u0644\\u0645\\u062d\\u0645\\u062f\", \"\\u0648\\u062d\\u062f\\u064a\\u062b\\u0627\", \"\\u064a\\u0628\\u0642\\u0649\", \"\\u0627\\u0644\\u0631\\u0633\\u0648\\u0644\", \"\\u0647\\u064a\\u0643\\u0644\\u060c\", \"\\u0642\\u062f\\u064a\\u0645\\u0627\", \"\\u0621\\u062d\\u062f\\u0627\\u062b\", \"\\u0644\\u0643\\u0644\", \"\\u0645\\u062d\\u0645\\u062f\", \"\\u0643\\u062a\\u0628\", \"\\u0627\\u0644\\u0642\\u0627\\u0646\\u0648\\u0646\", \"\\u062d\\u0633\\u064a\\u0646\", \"\\u0634\\u062e\\u0635\", \"\\u0621\\u0644\\u0649\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u0644\\u0647\", \"\\u0621\\u0634\\u0643\\u0627\\u0644\", \"\\u062d\\u064a\\u0627\\u062a\\u0647\", \"\\u0639\\u0627\\u0644\\u0645\", \"\\u0627\\u0644\\u0643\\u062a\\u0628\", \"\\u0648\\u0642\\u062f\", \"\\u0627\\u0644\\u0639\\u0635\\u0631\", \"\\u062d\\u0648\\u0644\", \"\\u0627\\u0644\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u0648\\u0647\\u064a\", \"\\u0627\\u0644\\u062f\\u0643\\u062a\\u0648\\u0631\", \"\\u064a\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\", \"\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u062e\\u0644\\u0627\\u0644\", \"\\u0630\\u0643\\u0631\\u062a\", \"\\u062f\\u0631\\u062c\\u0629\", \"\\u0627\\u0644\\u0646\\u062c\\u0627\\u062d\", \"\\u0645\\u0648\\u0636\\u0648\\u0639\\u0627\\u062a\", \"\\u0627\\u0644\\u0621\\u0646\\u0633\\u0627\\u0646\\u060c\", \"\\u0627\\u0644\\u0639\\u0644\\u0645\", \"\\u062f\\u0644\\u064a\\u0644\\u0627\", \"\\u0634\\u0647\\u0631\\u0629\", \"\\u0627\\u0644\\u0621\\u062f\\u0645\\u0627\\u0646\", \"\\u0627\\u0644\\u0627\\u062a\\u0635\\u0627\\u0644\", \"\\u0627\\u0644\\u0628\\u064a\\u0627\\u0646\\u060c\", \"\\u0621\\u062d\\u0642\\u064a\\u0642\\u0629\", \"\\u0641\\u062a\\u062a\\u062f\\u0627\\u062e\\u0644\", \"\\u0627\\u0644\\u0645\\u0627\\u062f\\u064a\", \"\\u0627\\u0644\\u0621\\u064a\\u0645\\u0627\\u0646\\u060c\", \"\\u0648\\u064a\\u0644\\u0648\\u0646\\u0647\", \"\\u0628\\u062d\\u0633\\u0646\", \"\\u0648\\u064a\\u0632\\u064a\\u0646\", \"\\u064a\\u062f\\u0631\\u064a\", \"\\u0628\\u0631\\u064a\\u0634\\u0629\", \"\\u0627\\u0644\\u0631\\u0627\\u0641\\u0639\\u064a\", \"\\u064a\\u0631\\u0633\\u0645\", \"\\u0628\\u062d\\u0644\\u064a\", \"\\u0635\\u0627\\u062f\\u0642\", \"\\u064a\\u0642\\u0631\\u0621\\u0647\", \"\\u0627\\u0644\\u0641\\u0646\\u0627\\u0646\\u060c\", \"\\u0627\\u0644\\u062d\\u062f\\u0648\\u062f\", \"\\u0645\\u0639\\u0627\\u0646\\u064a\\u0647\", \"\\u062a\\u0636\\u064a\\u0621\", \"\\u0648\\u0645\\u0639\\u0644\\u0645\\u0647\", \"\\u0621\\u064a\\u0644\\u0627\", \"\\u062a\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\", \"\\u0634\\u0645\\u0633\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u064a\\u0643\\u0648\\u0646\", \"\\u0648\\u0647\\u064a\", \"\\u0643\\u062a\\u0627\\u0628\\u0647\", \"\\u0627\\u0644\\u0642\\u0627\\u0631\\u0621\", \"\\u0621\\u0644\\u0649\", \"\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\", \"\\u0621\\u0644\\u064a\\u0647\\u0627\", \"\\u0627\\u0644\\u0634\\u0639\\u0648\\u0628\", \"\\u062d\\u0648\\u0644\", \"\\u0648\\u0621\\u0646\\u062a\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u0646\\u0641\\u0633\", \"\\u064a\\u0631\\u064a\\u062f\", \"\\u0639\\u0646\\u062f\\u0645\\u0627\", \"\\u0621\\u0643\\u062b\\u0631\", \"\\u0634\\u064a\\u0621\", \"\\u0627\\u0644\\u062a\\u0639\\u0627\\u0645\\u0644\", \"\\u0627\\u0644\\u0621\\u0644\\u064a\\u0627\\u0630\\u0629\", \"\\u0628\\u064a\\u0627\\u0646\\u0627\\u062a\", \"\\u0627\\u0644\\u0633\\u0645\\u0627\\u0621\", \"\\u0627\\u0644\\u0645\\u0627\\u0644\", \"\\u0627\\u0644\\u0648\\u062c\\u0648\\u062f\", \"\\u0627\\u0644\\u0646\\u0638\\u0631\", \"\\u0645\\u0639\\u0631\\u0641\\u0629\", \"\\u0627\\u0644\\u0634\\u0639\\u0631\", \"\\u0628\\u0634\\u0643\\u0644\", \"\\u0642\\u0645\\u0631\\u0627\", \"\\u0634\\u0645\\u0633\\u0627\", \"\\u0621\\u0639\\u0631\\u0641\", \"\\u0645\\u0628\\u062d\\u062b\", \"\\u0627\\u0644\\u062a\\u0632\\u0648\\u064a\\u0631\", \"\\u0627\\u0644\\u0621\\u062e\\u0628\\u0627\\u0631\", \"\\u0642\\u0627\\u0632\\u0627\\u0646\\u060c\", \"\\u062f\\u0641\\u0627\\u0639\\u0627\", \"\\u064a\\u0639\\u0644\\u0645\", \"\\u064a\\u0646\\u0632\\u0644\", \"\\u062c\\u0645\\u0639\\u064a\\u0627\\u062a\", \"\\u0628\\u0627\\u0644\\u062f\\u064a\\u0646\", \"\\u0635\\u0648\\u0631\\u0648\\u0627\", \"\\u0648\\u0633\\u0644\\u0645\", \"\\u0627\\u0644\\u0621\\u0633\", \"\\u0644\\u062d\\u0642\\u0627\", \"\\u0648\\u0621\\u0631\\u0627\\u062f\", \"\\u0627\\u0644\\u0645\\u0628\\u0634\\u0631\\u064a\\u0646\", \"\\u0648\\u0627\\u0644\\u0646\\u0628\\u064a\", \"\\u062a\\u0648\\u0644\\u0633\\u062a\\u0648\\u064a\", \"\\u0627\\u0644\\u0643\\u0627\\u062a\\u0628\", \"\\u0628\\u0627\\u0644\\u0646\\u0633\\u0628\\u0629\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u062a\\u0639\\u062f\", \"\\u062a\\u0643\\u0646\", \"\\u0621\\u0644\\u0649\", \"\\u0621\\u0647\\u0645\\u064a\\u0629\", \"\\u062e\\u0644\\u0627\\u0644\", \"\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\", \"\\u0643\\u0627\\u0646\\u062a\", \"\\u0639\\u0646\\u062f\\u0645\\u0627\", \"\\u0621\\u0643\\u062b\\u0631\", \"\\u0639\\u0627\\u0645\", \"\\u0621\\u0647\\u0645\", \"\\u0621\\u0644\\u0627\", \"\\u0627\\u0644\\u0643\\u062a\\u0628\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0621\\u062d\\u062f\", \"\\u0648\\u0647\\u064a\", \"\\u0646\\u0634\\u0621\\u062a\\u0647\", \"\\u0645\\u0648\\u0627\\u062c\\u0647\\u0629\", \"\\u0631\\u062d\\u0644\\u0629\", \"\\u0627\\u0644\\u0639\\u062b\\u0645\\u0627\\u0646\\u064a\\u0629\", \"\\u0641\\u0644\\u0633\\u0637\\u064a\\u0646\", \"\\u0621\\u0621\\u0644\\u064a\\u062a\\u0647\\u0627\\u060c\", \"\\u0627\\u0644\\u0627\\u0646\\u0641\\u0639\\u0627\\u0644\\u0627\\u062a\", \"\\u062f\\u064a\\u0643\\u0627\\u0631\\u062a\", \"\\u064a\\u0633\\u064a\\u0637\\u0631\", \"\\u0627\\u0646\\u0641\\u0639\\u0627\\u0644\\u0627\\u062a\", \"\\u0644\\u062e\\u062f\\u0645\\u0629\", \"\\u0644\\u0644\\u0639\\u0642\\u0644\", \"\\u0648\\u0627\\u0644\\u0639\\u0648\\u0627\\u0637\\u0641\", \"\\u0621\\u0639\\u0645\\u0627\\u0644\", \"\\u0646\\u062a\\u062d\\u062f\\u062b\", \"\\u0648\\u064a\\u0633\\u062e\\u0631\\u0647\\u0627\", \"\\u0634\\u062a\\u0649\", \"\\u0644\\u064a\\u0633\\u0645\\u062d\", \"\\u0648\\u064a\\u0641\\u0633\\u0631\", \"\\u0633\\u0639\\u0627\\u062f\\u0629\", \"\\u0644\\u064a\\u0644\\u0645\", \"\\u064a\\u062d\\u0644\\u0644\", \"\\u0648\\u0627\\u0644\\u0621\\u0647\\u0648\\u0627\\u0621\", \"\\u062a\\u0646\\u0641\\u0630\", \"\\u0627\\u0644\\u062a\\u0627\\u0633\\u0639\", \"\\u062a\\u0641\\u062a\\u0631\", \"\\u0648\\u062a\\u0642\\u0644\\u0644\", \"\\u0627\\u0644\\u0635\\u0647\\u064a\\u0648\\u0646\\u064a\\u0629\", \"\\u0627\\u0644\\u062a\\u062d\\u0631\\u0643\\u0627\\u062a\", \"\\u0627\\u0644\\u064a\\u0647\\u0648\\u062f\\u064a\\u0629\", \"\\u0648\\u0621\\u0635\\u0631\\u0627\\u0631\", \"\\u0648\\u0627\\u0644\\u0621\\u0631\\u0627\\u0636\\u064a\", \"\\u0639\\u0644\\u064a\\u0647\\u0627\", \"\\u0643\\u0627\\u0646\\u062a\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629\", \"\\u0627\\u0644\\u062d\\u0628\", \"\\u0627\\u0644\\u0646\\u0641\\u0633\", \"\\u0621\\u0644\\u0649\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\", \"\\u0621\\u0647\\u0645\\u064a\\u0629\", \"\\u0627\\u0644\\u0643\\u062b\\u064a\\u0631\", \"\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u0627\\u0644\\u0641\\u0631\\u062f\", \"\\u064a\\u062d\\u0627\\u0648\\u0644\", \"\\u0634\\u064a\\u0621\"], \"Freq\": [26.0, 13.0, 20.0, 8.0, 18.0, 23.0, 8.0, 8.0, 11.0, 11.0, 6.0, 11.0, 14.0, 6.0, 11.0, 6.0, 6.0, 6.0, 10.0, 10.0, 9.0, 6.0, 6.0, 15.0, 6.0, 6.0, 6.0, 19.0, 9.0, 12.0, 6.374892359009783, 6.3698040865163925, 6.369001663497079, 6.368236800704202, 6.365218324325168, 6.363775670173424, 6.363065440437181, 6.36242805477645, 6.362337568776399, 6.362200417040475, 6.361238078511638, 6.361171494473865, 6.360919385681273, 6.360126637265738, 6.359718027529663, 6.359642337982451, 6.359069829076472, 6.358705039604572, 6.3582565932647, 6.358122856094815, 6.357648231415307, 6.357413195452912, 6.357347749603819, 6.356757029678962, 6.355074217715765, 4.82906880166128, 4.82906595618958, 4.829064818000901, 4.829061403434861, 4.829060265246181, 9.491374750701704, 7.928251863607751, 7.91993511892389, 7.949369816374189, 11.035908171181566, 12.60087663121994, 17.28014671343959, 21.969937073627342, 18.87169870828517, 9.480508463374917, 6.389975635395512, 6.389289307621547, 6.388951834677963, 6.3860972574688315, 6.383156747014369, 6.376635494973014, 6.362639757870907, 6.294488557626641, 6.286802439370973, 6.286624670276216, 4.767259894009302, 4.767222104770596, 4.767168880490729, 4.767167816005132, 4.767159832363151, 4.767156106663561, 4.767142268350795, 4.767134284708815, 4.767112994996868, 4.767090108556525, 4.767087447342531, 4.7670768024865575, 4.767037948762255, 4.767033690819865, 4.7670198525071, 4.766998562795153, 4.766963967013239, 4.766903823576988, 4.761144956495323, 4.749622432146804, 4.747216162453993, 4.746981975622576, 4.7469590891822335, 4.746770675231502, 4.745757817185623, 4.74542569767925, 4.744221764468647, 10.914759490168617, 14.00091294055, 13.956354637930511, 7.810094103006512, 6.291020995793272, 6.284314204287167, 7.841142486667229, 21.69997321211089, 20.158847156777345, 13.985315033092025, 7.8247637790235975, 6.296404099459074, 6.300335244770088, 6.3157128037094115, 6.289833562109428, 6.30492264545187, 6.300692379688, 6.294451300630734, 4.79700587954166, 4.781396262742115, 4.769689050142456, 4.769249949833549, 4.769183951726513, 4.768583581849607, 4.767836845203066, 4.7677735083100234, 7.796508837962629, 7.772416602506405, 6.258847080883741, 6.256071772806099, 4.742490277428831, 4.741642743842187, 4.740883191321969, 4.740095526508337, 4.732800906965301, 4.729414937402932, 4.727409073208006, 4.7260258442524075, 4.7259743050478145, 4.725903503716252, 4.7258759120208635, 4.725763462847206, 4.72570411467222, 4.725687455535381, 4.725670796398543, 4.72457806114156, 4.724251646179137, 4.724079328232467, 4.723706580045712, 4.723460337179321, 4.722574799936765, 4.722350942785502, 4.722136976996736, 3.212976139758897, 3.2129743176658057, 3.2129735367687666, 6.27394130005522, 6.26780188753231, 6.274694084801097, 32.286294291507076, 7.805550584481573, 9.328741798824362, 7.794488397022969, 6.257287369197262, 15.472928205634844, 7.816735633074359, 4.740522937487842, 4.739368771663769, 4.755850905173083, 4.752496171492287, 4.751097324595903, 4.748059114515032, 4.736713201132152, 4.736433119394059, 4.736067138981644, 4.73533049277458, 6.1979218083693155, 6.18575649371422, 6.177520425649892, 4.690784034963316, 4.688829529687667, 4.687451011194009, 4.685815346930499, 4.68271775220576, 4.678255952283573, 3.1784724985391377, 3.178465341891032, 3.1784646015481246, 3.1784623805194023, 3.1781731532235615, 3.1773067052408845, 3.1772435293127828, 3.1771756645462674, 3.177163078716841, 3.1770974349790477, 3.1769046990421432, 3.176865460868049, 3.176843990923733, 3.1768351068088436, 3.1768094415880523, 3.1767963621966877, 3.1767608257371305, 3.1767494738125497, 3.1767243021536964, 3.176723561810789, 3.1767159116007457, 6.206931287990953, 4.700773728594406, 28.885327460403353, 4.675237821030899, 4.6750394091317045, 18.29968740253751, 6.194543870463624, 6.203288307324397, 7.6993846066088, 6.197675027400168, 4.688640989027238, 6.2110885601972115, 4.69295965598732, 4.683030670474639, 4.688546225135085, 4.678405007988938, 6.204780838625801, 4.68077805378826, 4.6754169840145, 3.1950361904073485, 3.1824187730167752, 7.630356232678246, 6.146152814753505, 6.141900458891465, 4.648414981094786, 4.648415456537077, 4.648414505652493, 4.648412128441032, 4.648406423133524, 4.6484073740181096, 4.648399291499141, 4.648401668710602, 4.648397389729972, 4.648392159864756, 4.648394537076218, 4.6483935861916335, 4.64839073353788, 4.6483888317687105, 4.648387880884126, 4.648385028230373, 4.648381224692034, 4.648372666730774, 4.647251098363315, 4.647212112095349, 4.647169322289045, 4.647124155271279, 4.647089923426236, 4.646997687621536, 4.646904976374544, 4.646893565759529, 4.64686218656824, 7.663920081300869, 9.147057082164054, 7.6487501440814905, 6.1487125960550735, 9.148803857145845, 13.625258492761867, 10.66174871252274, 12.139867419991042, 7.660327639340496, 6.143455630629472, 4.66211009632355, 4.6551348824536944, 4.65405420212337, 4.653834547784342, 4.6489132446170816], \"Total\": [26.0, 13.0, 20.0, 8.0, 18.0, 23.0, 8.0, 8.0, 11.0, 11.0, 6.0, 11.0, 14.0, 6.0, 11.0, 6.0, 6.0, 6.0, 10.0, 10.0, 9.0, 6.0, 6.0, 15.0, 6.0, 6.0, 6.0, 19.0, 9.0, 12.0, 6.994767497019004, 6.994886890661265, 6.994854583957156, 6.994852786757414, 6.994815300453601, 6.994796181259182, 6.994787873092798, 6.9947654502682965, 6.9947757937940125, 6.994774677325789, 6.994759501996999, 6.99475623062433, 6.994752719850925, 6.994732302085975, 6.994743768618951, 6.9947366657694, 6.994727037078354, 6.994724829155631, 6.994707459038789, 6.994703552221492, 6.994707168720548, 6.994686335445333, 6.994701309443291, 6.994684490977662, 6.994682491789566, 5.4372423522344935, 5.437239970812061, 5.437239987701946, 5.43723988093652, 5.437239363265243, 11.62409795664619, 10.066279663752162, 10.08245528019872, 11.590015707226762, 19.276902352259878, 26.813472402733986, 52.88308862227606, 91.06778438667246, 112.34203503696398, 20.811580094262634, 8.52498716801094, 10.024273409838807, 11.570219861051015, 14.630111231193162, 14.660415091461967, 11.559820521997082, 8.524602288475542, 6.915673175879628, 6.915657394797089, 6.915651912658633, 5.37774359794626, 5.377738309564725, 5.377737748759358, 5.37774032796183, 5.377744221678395, 5.377742868195684, 5.377740203358734, 5.377743178886823, 5.377739054808703, 5.377740526776207, 5.377740213677881, 5.377735368806389, 5.377733232756069, 5.377738905597057, 5.377740977420709, 5.377737972506454, 5.377734499587999, 5.377734449844648, 5.377689520828096, 5.37795812685385, 5.3779046903148, 5.377865008396591, 5.377886975829046, 5.3778802911694195, 5.377883780180094, 5.3778769094064724, 5.377896388504847, 13.043246487365867, 20.722685707129894, 23.805802285963118, 11.452720398488136, 8.429043929628627, 8.473389908388127, 12.982818525003012, 91.06778438667246, 112.34203503696398, 52.88308862227606, 15.979760801675473, 9.944801177432236, 11.41432901888643, 14.660415091461967, 14.51687669618738, 14.648647781258012, 16.09031127761284, 17.648458421022696, 20.811580094262634, 20.59907650914616, 9.920394953624745, 11.43351088304048, 9.947994539495852, 13.09417993809251, 16.047162543187522, 6.891264978700761, 8.414395312462595, 8.413853803272508, 6.884216270953174, 6.883832928297621, 5.354056971020866, 5.35403254859639, 5.354068463220785, 5.354019609481123, 5.353873252762001, 5.353773537812584, 5.353727157699187, 5.353703844026935, 5.353701638998972, 5.353697521561844, 5.353694442073222, 5.353686330070414, 5.353694394304253, 5.353692416954061, 5.353694934778515, 5.353670701347946, 5.353665878560062, 5.353662733910896, 5.353651471179076, 5.353640121148605, 5.353628526556229, 5.353624731822197, 5.353620905442437, 3.8239155602575554, 3.823915030465473, 3.8239147405674374, 8.397545906448805, 8.397716723938654, 8.441492554321423, 112.34203503696398, 13.003302256444325, 20.59907650914616, 16.065895871617037, 9.911172510497511, 91.06778438667246, 26.575334624634955, 6.911624019165984, 6.891809084716656, 17.648458421022696, 9.852876030948151, 52.88308862227606, 26.813472402733986, 6.8917792419764305, 9.895052751826329, 22.136665499443527, 9.852626586480895, 6.818651316441273, 6.818683995461387, 6.819224670182132, 5.304801200389967, 5.304817503878869, 5.3048262529544665, 5.304916452069062, 5.304744276844523, 5.304906939650141, 3.7910608970963353, 3.791058445649214, 3.7910577821407934, 3.7910576054627985, 3.791059093854985, 3.791078297509474, 3.791071454160515, 3.7910791358795697, 3.7910788587167246, 3.7910887122954495, 3.791093626650235, 3.7910788165340112, 3.791074440923246, 3.791082157954286, 3.7910820147752045, 3.7910765160713336, 3.791081483491205, 3.7910975005167957, 3.791077083466006, 3.7910824899326547, 3.791078593254367, 8.348358382344518, 6.834475110023474, 112.34203503696398, 6.834798508850496, 6.834789013230445, 91.06778438667246, 14.354718730808854, 16.047162543187522, 26.575334624634955, 18.93111605546575, 9.895052751826329, 22.136665499443527, 11.459898241061289, 11.516010871636919, 14.45916699782393, 14.51687669618738, 52.88308862227606, 19.276902352259878, 20.59907650914616, 6.866502393860976, 5.328694820951858, 8.262051920512913, 6.762030898206645, 6.762132306862647, 5.262421386381312, 5.262421996789729, 5.262421744368954, 5.262420199671426, 5.262417468392965, 5.262418863785092, 5.262412376649955, 5.262415482143351, 5.262415702424194, 5.262411839162273, 5.2624150915174335, 5.2624158851425795, 5.262412946261499, 5.262411717150411, 5.262410683688165, 5.262408513860871, 5.262410948056682, 5.262406720954075, 5.26243827240123, 5.262444092010589, 5.262441310574561, 5.262445587606303, 5.262444060985367, 5.26244091918999, 5.262447652684024, 5.262444155880111, 5.262441907256385, 11.304819292167478, 18.93111605546575, 15.929750125310068, 9.821962019489948, 26.813472402733986, 91.06778438667246, 52.88308862227606, 112.34203503696398, 26.575334624634955, 14.354718730808854, 11.40446552210033, 11.40893188930398, 6.792108991420063, 6.792106195784777, 9.852626586480895], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.9491, -5.9499, -5.95, -5.9502, -5.9506, -5.9509, -5.951, -5.9511, -5.9511, -5.9511, -5.9513, -5.9513, -5.9513, -5.9514, -5.9515, -5.9515, -5.9516, -5.9517, -5.9517, -5.9518, -5.9518, -5.9519, -5.9519, -5.952, -5.9522, -6.2268, -6.2268, -6.2268, -6.2268, -6.2268, -5.5511, -5.7311, -5.7321, -5.7284, -5.4003, -5.2677, -4.9519, -4.7118, -4.8638, -5.5523, -5.9468, -5.9469, -5.9469, -5.9474, -5.9478, -5.9488, -5.951, -5.8949, -5.8961, -5.8961, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1728, -6.1741, -6.1765, -6.177, -6.177, -6.177, -6.1771, -6.1773, -6.1774, -6.1776, -5.3444, -5.0954, -5.0986, -5.6791, -5.8954, -5.8965, -5.6752, -4.6572, -4.7309, -5.0965, -5.6773, -5.8946, -5.8939, -5.8915, -5.8956, -5.8932, -5.8939, -5.8949, -6.1666, -6.1698, -6.1723, -6.1724, -6.1724, -6.1725, -6.1727, -6.1727, -5.6587, -5.6618, -5.8784, -5.8789, -6.1559, -6.156, -6.1562, -6.1564, -6.1579, -6.1586, -6.159, -6.1593, -6.1593, -6.1594, -6.1594, -6.1594, -6.1594, -6.1594, -6.1594, -6.1596, -6.1597, -6.1597, -6.1598, -6.1599, -6.1601, -6.1601, -6.1602, -6.5452, -6.5452, -6.5452, -5.876, -5.877, -5.8759, -4.2378, -5.6576, -5.4793, -5.659, -5.8787, -4.9733, -5.6562, -6.1563, -6.1565, -6.153, -6.1538, -6.154, -6.1547, -6.1571, -6.1571, -6.1572, -6.1574, -5.8349, -5.8368, -5.8382, -6.1135, -6.1139, -6.1142, -6.1146, -6.1152, -6.1162, -6.5027, -6.5027, -6.5027, -6.5027, -6.5028, -6.5031, -6.5031, -6.5031, -6.5031, -6.5031, -6.5032, -6.5032, -6.5032, -6.5032, -6.5032, -6.5032, -6.5032, -6.5032, -6.5032, -6.5032, -6.5032, -5.8334, -6.1114, -4.2958, -6.1168, -6.1169, -4.7522, -5.8354, -5.834, -5.618, -5.8349, -6.1139, -5.8328, -6.113, -6.1151, -6.114, -6.1161, -5.8338, -6.1156, -6.1168, -6.4975, -6.5015, -5.5896, -5.8059, -5.8066, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0852, -6.0854, -6.0854, -6.0854, -6.0854, -6.0854, -6.0855, -6.0855, -6.0855, -6.0855, -5.5852, -5.4083, -5.5871, -5.8054, -5.4081, -5.0098, -5.255, -5.1252, -5.5856, -5.8063, -6.0822, -6.0837, -6.084, -6.084, -6.0851], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.4229, 1.4221, 1.422, 1.4219, 1.4214, 1.4212, 1.4211, 1.421, 1.421, 1.4209, 1.4208, 1.4208, 1.4207, 1.4206, 1.4206, 1.4205, 1.4205, 1.4204, 1.4203, 1.4203, 1.4202, 1.4202, 1.4202, 1.4201, 1.4198, 1.3971, 1.3971, 1.3971, 1.3971, 1.3971, 1.313, 1.277, 1.2743, 1.1387, 0.958, 0.7606, 0.3972, 0.0938, -0.2682, 0.7295, 1.2275, 1.0653, 0.9219, 0.6868, 0.6842, 0.9208, 1.2232, 1.4886, 1.4873, 1.4873, 1.4622, 1.4622, 1.4622, 1.4622, 1.4622, 1.4622, 1.4622, 1.4622, 1.4621, 1.4621, 1.4621, 1.4621, 1.4621, 1.4621, 1.4621, 1.4621, 1.4621, 1.4621, 1.4609, 1.4584, 1.4579, 1.4579, 1.4579, 1.4578, 1.4576, 1.4576, 1.4573, 1.4045, 1.1906, 1.0487, 1.1999, 1.2901, 1.2838, 1.0784, 0.1484, -0.1352, 0.2526, 0.8686, 1.1256, 0.9884, 0.7406, 0.7463, 0.7397, 0.6451, 0.5517, 0.1152, 0.1222, 0.8504, 0.7083, 0.8475, 0.5726, 0.369, 1.2143, 1.5285, 1.5255, 1.5096, 1.5092, 1.4835, 1.4833, 1.4832, 1.483, 1.4815, 1.4808, 1.4804, 1.4801, 1.4801, 1.4801, 1.4801, 1.48, 1.48, 1.48, 1.48, 1.4798, 1.4797, 1.4797, 1.4796, 1.4796, 1.4794, 1.4793, 1.4793, 1.4307, 1.4307, 1.4307, 1.3133, 1.3123, 1.3082, 0.3579, 1.0944, 0.8127, 0.8815, 1.1449, -0.1677, 0.3811, 1.2277, 1.2304, 0.2935, 0.8757, -0.8049, -0.1264, 1.2298, 0.868, 0.0628, 0.8721, 1.5627, 1.5607, 1.5593, 1.5351, 1.5347, 1.5344, 1.534, 1.5334, 1.5324, 1.4819, 1.4819, 1.4819, 1.4819, 1.4818, 1.4815, 1.4815, 1.4815, 1.4815, 1.4814, 1.4814, 1.4814, 1.4814, 1.4814, 1.4814, 1.4814, 1.4813, 1.4813, 1.4813, 1.4813, 1.4813, 1.3617, 1.2839, 0.2999, 1.2784, 1.2783, 0.0534, 0.8177, 0.7077, 0.4193, 0.5415, 0.9112, 0.3872, 0.7653, 0.7583, 0.5319, 0.5258, -0.4846, 0.2427, 0.1752, 0.8931, 1.1427, 1.616, 1.6, 1.5993, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5715, 1.5712, 1.5712, 1.5712, 1.5712, 1.5712, 1.5712, 1.5711, 1.5711, 1.5711, 1.3068, 0.9682, 0.9619, 1.2272, 0.6202, -0.2041, 0.0941, -0.5295, 0.4516, 0.8468, 0.801, 0.7991, 1.3175, 1.3175, 0.9444]}, \"token.table\": {\"Topic\": [5, 1, 2, 3, 4, 2, 4, 3, 2, 2, 3, 5, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 4, 2, 4, 5, 3, 2, 4, 3, 4, 1, 1, 2, 4, 2, 2, 4, 1, 4, 3, 3, 3, 1, 3, 5, 5, 3, 1, 2, 3, 4, 5, 5, 4, 4, 3, 5, 3, 1, 2, 3, 4, 5, 1, 1, 3, 2, 4, 1, 4, 2, 3, 5, 2, 1, 1, 2, 3, 4, 5, 5, 3, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 5, 3, 2, 3, 5, 3, 3, 4, 2, 4, 1, 3, 4, 1, 1, 2, 3, 4, 5, 2, 3, 4, 1, 4, 5, 2, 4, 5, 3, 4, 4, 2, 2, 2, 1, 2, 3, 4, 1, 3, 5, 4, 2, 5, 5, 2, 4, 2, 3, 4, 2, 1, 3, 3, 1, 3, 4, 4, 1, 2, 4, 5, 3, 4, 3, 3, 4, 2, 5, 3, 4, 1, 2, 3, 4, 5, 4, 4, 1, 2, 1, 1, 2, 3, 4, 2, 5, 1, 2, 4, 5, 1, 1, 2, 3, 4, 3, 5, 2, 4, 5, 1, 1, 5, 5, 2, 3, 5, 1, 3, 4, 3, 3, 5, 3, 1, 1, 4, 1, 2, 4, 1, 2, 3, 4, 1, 3, 1, 3, 4, 5, 1, 3, 3, 4, 1, 2, 1, 3, 1, 1, 4, 5, 4, 2, 4, 1, 4, 5, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 5, 2, 4, 5, 1, 2, 3, 5, 5, 1, 2, 5, 5, 4, 1, 2, 4, 5, 1, 2, 5, 3, 4, 2, 2, 4, 3, 2, 5, 2, 4, 1, 1, 2, 4, 5, 3, 5, 5, 5, 1, 1, 2, 5, 4, 5, 2, 4, 2, 1, 2, 3, 3, 2, 2, 1, 2, 3, 4, 5, 3, 5, 5, 3, 2, 1, 2, 5, 3, 5, 5, 3, 3, 2, 3, 1, 5, 1, 1, 2, 3, 5, 4, 3, 2, 3, 4, 1, 2, 5, 4], \"Freq\": [0.950132958363913, 0.5706311003183788, 0.10375110914879616, 0.10375110914879616, 0.2593777728719904, 0.8433483190442637, 0.15333605800804795, 0.9339288037511414, 0.929759767469447, 0.6033303122857615, 0.20111010409525384, 0.20111010409525384, 0.7913359047029757, 0.9501339846064785, 0.13552176591706705, 0.22586960986177843, 0.22586960986177843, 0.2710435318341341, 0.13552176591706705, 0.13832055472497104, 0.13832055472497104, 0.20748083208745655, 0.34580138681242756, 0.20748083208745655, 0.2415782941044039, 0.2415782941044039, 0.16471247325300264, 0.19765496790360318, 0.15373164170280249, 0.28936759211062196, 0.7234189802765548, 0.4341781243290269, 0.17367124973161077, 0.4341781243290269, 0.1393270072026904, 0.4179810216080712, 0.4179810216080712, 0.7845363203769613, 0.9297580478796655, 0.7913330139709308, 0.9338777899030831, 0.791331957369428, 0.9195838029815235, 0.5190392003563249, 0.17301306678544165, 0.25951960017816245, 0.8675964781763231, 0.9297208870097771, 0.8799351904258483, 0.7742536266957526, 0.172056361487945, 0.871607440577993, 0.9339339736439464, 0.9339033189514822, 0.5985471220398887, 0.19951570734662957, 0.19951570734662957, 0.9501328481543639, 0.9339207130608055, 0.4324515466502773, 0.24025085925015405, 0.14415051555009242, 0.14415051555009242, 0.9501288588682529, 0.9501294317180885, 0.7913315855203602, 0.8799394075970237, 0.3054379556800393, 0.6108759113600786, 0.9339466717343421, 0.85778543271185, 0.5040121913869048, 0.20160487655476192, 0.20160487655476192, 0.20160487655476192, 0.8577735919416547, 0.8577805334879534, 0.9339386523607254, 0.9297337399568276, 0.9425423896436382, 0.919584202887696, 0.9425236025591338, 0.2901995652252207, 0.7254989130630518, 0.9501288644698247, 0.9297588897375523, 0.8577850315349662, 0.07525775416374357, 0.07525775416374357, 0.3010310166549743, 0.3010310166549743, 0.3010310166549743, 0.8873073918652541, 0.7144799232029716, 0.23815997440099054, 0.20104554662344604, 0.5026138665586151, 0.20104554662344604, 0.20104554662344604, 0.12555124746258822, 0.12555124746258822, 0.18832687119388233, 0.12555124746258822, 0.5022049898503529, 0.18644760491203374, 0.3728952098240675, 0.18644760491203374, 0.18644760491203374, 0.9338712731416159, 0.9297673249142995, 0.29445935018511077, 0.736148375462777, 0.9339460097386129, 0.6053774156029514, 0.3026887078014757, 0.7118245022913711, 0.2372748340971237, 0.8577840510863372, 0.23956805738355574, 0.7187041721506672, 0.8577815523299144, 0.16912636479968, 0.17802775242071578, 0.28484440387314525, 0.25814024101003785, 0.10681665145242947, 0.41331204539167865, 0.20665602269583933, 0.3444267044930655, 0.26305485287200886, 0.26305485287200886, 0.43842475478668147, 0.500633276010064, 0.18773747850377404, 0.31289579750629004, 0.9339332553718651, 0.942539492893773, 0.7913318389340791, 0.9297587608921013, 0.9297578675914601, 0.9297595484461091, 0.857783033635387, 0.929758786689344, 0.9508128126600509, 0.9425219124892842, 0.4848309015983502, 0.18647342369167316, 0.3356521626450117, 0.9425379383943636, 0.9297589480116678, 0.9501282159927678, 0.9501336657593031, 0.9297585605349387, 0.7913323905265773, 0.9297585064033108, 0.29263403082217543, 0.7315850770554385, 0.9297581015950614, 0.8577942304244471, 0.9339359259649113, 0.9339400422684933, 0.8577843020840477, 0.9339344248995488, 0.7913352176162013, 0.8798654231522406, 0.17530124812779588, 0.2629518721916938, 0.17530124812779588, 0.43825312031948965, 0.7144944566950643, 0.23816481889835475, 0.7845361522046628, 0.29262018440048615, 0.7315504610012153, 0.9297589866953809, 0.9501293610539274, 0.29262059093974946, 0.7315514773493736, 0.38184903702555756, 0.38184903702555756, 0.15273961481022302, 0.15273961481022302, 0.9501299095938887, 0.7913315237879879, 0.791331477181671, 0.23603304245684775, 0.7080991273705433, 0.8577869609632098, 0.16998651828005698, 0.33997303656011396, 0.28331086380009496, 0.16998651828005698, 0.5256550770590415, 0.43804589754920126, 0.18694893828900522, 0.3115815638150087, 0.37389787657801044, 0.12463262552600347, 0.8577733715524444, 0.8577914137419148, 0.8675944983818353, 0.9507516230133813, 0.7913314683766552, 0.9338755329963015, 0.9501328937290596, 0.7255561954813514, 0.29022247819254055, 0.9682824650541962, 0.9195843084968277, 0.8577918928521885, 0.9501348907447387, 0.9501339516165075, 0.6161990159989658, 0.15404975399974144, 0.23107463099961217, 0.23692492614663827, 0.7107747784399149, 0.7913358678236535, 0.9338692686406568, 0.5074788896252965, 0.5074788896252965, 0.9339420070426832, 0.8577858632474823, 0.8577940042279246, 0.7913307797103601, 0.4092653558966636, 0.4092653558966636, 0.13642178529888788, 0.17452161947074865, 0.17452161947074865, 0.261782429206123, 0.4363040486768716, 0.7038133761085681, 0.234604458702856, 0.8577892835741889, 0.1769156983681903, 0.1769156983681903, 0.7076627934727612, 0.7934575237552974, 0.19836438093882436, 0.5053030161033907, 0.5053030161033907, 0.8577694098256944, 0.9297595570462651, 0.9195842057442319, 0.933932870713131, 0.8577883671417526, 0.794732539451227, 0.19868313486280675, 0.8872940853154876, 0.7913314105230275, 0.929731560222582, 0.7913357293245986, 0.15846926252051824, 0.3169385250410365, 0.4754077875615548, 0.7038451527658286, 0.23461505092194287, 0.3214638260148643, 0.2647349155416529, 0.0945481841220189, 0.11345782094642268, 0.20800600506844158, 0.18673095008041085, 0.12448730005360724, 0.49794920021442896, 0.18673095008041085, 0.6985239944438069, 0.26194649791642755, 0.9297593981664759, 0.7913309204943022, 0.95013341382021, 0.09651258665337357, 0.675588106573615, 0.14476887998006036, 0.09651258665337357, 0.9501345850784491, 0.8577831705500903, 0.9297369852522105, 0.9501344822344432, 0.9501352825099567, 0.7913355940198266, 0.21003282896910414, 0.5880919211134916, 0.1260196973814625, 0.08401313158764166, 0.5185726867816817, 0.25928634339084083, 0.17285756226056054, 0.933947339251655, 0.9425525037701163, 0.9297585407763647, 0.37532642930426674, 0.5629896439564002, 0.8715589057415323, 0.9297585623190181, 0.9501346821224759, 0.43690365602758136, 0.43690365602758136, 0.8577890128084478, 0.8577914493449056, 0.9297349277843221, 0.791327577196589, 0.9501288473366766, 0.5074660418232062, 0.5074660418232062, 0.9501292533235373, 0.9501356062219188, 0.9195842209446148, 0.8577944755952633, 0.8675971659327454, 0.9501340243783886, 0.7913307104149275, 0.9501285888400645, 0.9297331874902797, 0.7913308095968185, 0.9297301250066076, 0.34132843349521813, 0.4095941201942618, 0.2047970600971309, 0.7845362608998191, 0.9297584284913101, 0.9297579754284828, 0.8577921678942344, 0.24272932807351627, 0.4369127905323293, 0.24272932807351627, 0.09709173122940651, 0.9339345191835109, 0.9501340949062675, 0.9501347041518624, 0.93393451085037, 0.9297343431407527, 0.17492439727910994, 0.43731099319777483, 0.43731099319777483, 0.294459471384769, 0.7361486784619226, 0.9501348430126716, 0.9339348641259276, 0.9339394936885405, 0.2902008218455991, 0.7255020546139977, 0.8577781888838311, 0.9501331726250575, 0.8577878320084003, 0.41011308151965903, 0.20505654075982951, 0.20505654075982951, 0.136704360506553, 0.7913294115936272, 0.9339439870544132, 0.23071062571918804, 0.6152283352511682, 0.15380708381279204, 0.690249280250046, 0.1725623200625115, 0.1725623200625115, 0.7913283858016359], \"Term\": [\"\\u0621\\u0621\\u0644\\u064a\\u062a\\u0647\\u0627\\u060c\", \"\\u0621\\u062d\\u062f\", \"\\u0621\\u062d\\u062f\", \"\\u0621\\u062d\\u062f\", \"\\u0621\\u062d\\u062f\", \"\\u0621\\u062d\\u062f\\u0627\\u062b\", \"\\u0621\\u062d\\u062f\\u0627\\u062b\", \"\\u0621\\u062d\\u0642\\u064a\\u0642\\u0629\", \"\\u0621\\u0633\\u0647\\u0628\\u062a\", \"\\u0621\\u0634\\u0643\\u0627\\u0644\", \"\\u0621\\u0634\\u0643\\u0627\\u0644\", \"\\u0621\\u0634\\u0643\\u0627\\u0644\", \"\\u0621\\u0639\\u0631\\u0641\", \"\\u0621\\u0639\\u0645\\u0627\\u0644\", \"\\u0621\\u0643\\u062b\\u0631\", \"\\u0621\\u0643\\u062b\\u0631\", \"\\u0621\\u0643\\u062b\\u0631\", \"\\u0621\\u0643\\u062b\\u0631\", \"\\u0621\\u0643\\u062b\\u0631\", \"\\u0621\\u0644\\u0627\", \"\\u0621\\u0644\\u0627\", \"\\u0621\\u0644\\u0627\", \"\\u0621\\u0644\\u0627\", \"\\u0621\\u0644\\u0627\", \"\\u0621\\u0644\\u0649\", \"\\u0621\\u0644\\u0649\", \"\\u0621\\u0644\\u0649\", \"\\u0621\\u0644\\u0649\", \"\\u0621\\u0644\\u0649\", \"\\u0621\\u0644\\u064a\\u0647\\u0627\", \"\\u0621\\u0644\\u064a\\u0647\\u0627\", \"\\u0621\\u0647\\u0645\", \"\\u0621\\u0647\\u0645\", \"\\u0621\\u0647\\u0645\", \"\\u0621\\u0647\\u0645\\u064a\\u0629\", \"\\u0621\\u0647\\u0645\\u064a\\u0629\", \"\\u0621\\u0647\\u0645\\u064a\\u0629\", \"\\u0621\\u064a\\u0644\\u0627\", \"\\u0627\\u062d\\u062a\\u0641\\u0649\", \"\\u0627\\u0644\\u0621\\u062e\\u0628\\u0627\\u0631\", \"\\u0627\\u0644\\u0621\\u062f\\u0645\\u0627\\u0646\", \"\\u0627\\u0644\\u0621\\u0633\", \"\\u0627\\u0644\\u0621\\u0633\\u0641\\u0627\\u0631\", \"\\u0627\\u0644\\u0621\\u0633\\u0644\\u0627\\u0645\\u064a\", \"\\u0627\\u0644\\u0621\\u0633\\u0644\\u0627\\u0645\\u064a\", \"\\u0627\\u0644\\u0621\\u0633\\u0644\\u0627\\u0645\\u064a\", \"\\u0627\\u0644\\u0621\\u0634\\u0627\\u0639\\u0629\", \"\\u0627\\u0644\\u0621\\u0639\\u0644\\u0627\\u0645\", \"\\u0627\\u0644\\u0621\\u0644\\u064a\\u0627\\u0630\\u0629\", \"\\u0627\\u0644\\u0621\\u0645\\u0627\\u0645\", \"\\u0627\\u0644\\u0621\\u0645\\u0627\\u0645\", \"\\u0627\\u0644\\u0621\\u0646\\u0633\\u0627\\u0646\\u060c\", \"\\u0627\\u0644\\u0621\\u064a\\u0645\\u0627\\u0646\\u060c\", \"\\u0627\\u0644\\u0627\\u062a\\u0635\\u0627\\u0644\", \"\\u0627\\u0644\\u0627\\u062c\\u062a\\u0645\\u0627\\u0639\\u064a\", \"\\u0627\\u0644\\u0627\\u062c\\u062a\\u0645\\u0627\\u0639\\u064a\", \"\\u0627\\u0644\\u0627\\u062c\\u062a\\u0645\\u0627\\u0639\\u064a\", \"\\u0627\\u0644\\u0627\\u0646\\u0641\\u0639\\u0627\\u0644\\u0627\\u062a\", \"\\u0627\\u0644\\u0628\\u064a\\u0627\\u0646\\u060c\", \"\\u0627\\u0644\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u0627\\u0644\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u0627\\u0644\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u0627\\u0644\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u0627\\u0644\\u062a\\u0627\\u0633\\u0639\", \"\\u0627\\u0644\\u062a\\u062d\\u0631\\u0643\\u0627\\u062a\", \"\\u0627\\u0644\\u062a\\u0632\\u0648\\u064a\\u0631\", \"\\u0627\\u0644\\u062a\\u0639\\u0627\\u0645\\u0644\", \"\\u0627\\u0644\\u062d\\u0628\", \"\\u0627\\u0644\\u062d\\u0628\", \"\\u0627\\u0644\\u062d\\u062f\\u0648\\u062f\", \"\\u0627\\u0644\\u062e\\u0637\\u0627\\u0628\", \"\\u0627\\u0644\\u062f\\u0643\\u062a\\u0648\\u0631\", \"\\u0627\\u0644\\u062f\\u0643\\u062a\\u0648\\u0631\", \"\\u0627\\u0644\\u062f\\u0643\\u062a\\u0648\\u0631\", \"\\u0627\\u0644\\u062f\\u0643\\u062a\\u0648\\u0631\", \"\\u0627\\u0644\\u0630\\u0643\\u0631\", \"\\u0627\\u0644\\u0631\\u0627\\u0634\\u062f\", \"\\u0627\\u0644\\u0631\\u0627\\u0641\\u0639\\u064a\", \"\\u0627\\u0644\\u0631\\u0633\\u0648\\u0644\", \"\\u0627\\u0644\\u0633\\u0645\\u0627\\u0621\", \"\\u0627\\u0644\\u0634\\u0631\\u0639\\u064a\\u0629\", \"\\u0627\\u0644\\u0634\\u0639\\u0631\", \"\\u0627\\u0644\\u0634\\u0639\\u0648\\u0628\", \"\\u0627\\u0644\\u0634\\u0639\\u0648\\u0628\", \"\\u0627\\u0644\\u0635\\u0647\\u064a\\u0648\\u0646\\u064a\\u0629\", \"\\u0627\\u0644\\u0637\\u0648\\u0627\\u0644\\u060c\", \"\\u0627\\u0644\\u0639\\u0627\\u062f\\u0644\\u060c\", \"\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\", \"\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\", \"\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\", \"\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\", \"\\u0627\\u0644\\u0639\\u0627\\u0644\\u0645\", \"\\u0627\\u0644\\u0639\\u062b\\u0645\\u0627\\u0646\\u064a\\u0629\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629\", \"\\u0627\\u0644\\u0639\\u0631\\u0628\\u064a\\u0629\", \"\\u0627\\u0644\\u0639\\u0635\\u0631\", \"\\u0627\\u0644\\u0639\\u0635\\u0631\", \"\\u0627\\u0644\\u0639\\u0635\\u0631\", \"\\u0627\\u0644\\u0639\\u0635\\u0631\", \"\\u0627\\u0644\\u0639\\u0644\\u0645\", \"\\u0627\\u0644\\u063a\\u0631\\u0628\\u064a\\u0629\", \"\\u0627\\u0644\\u0641\\u0631\\u062f\", \"\\u0627\\u0644\\u0641\\u0631\\u062f\", \"\\u0627\\u0644\\u0641\\u0646\\u0627\\u0646\\u060c\", \"\\u0627\\u0644\\u0642\\u0627\\u0631\\u0621\", \"\\u0627\\u0644\\u0642\\u0627\\u0631\\u0621\", \"\\u0627\\u0644\\u0642\\u0627\\u0646\\u0648\\u0646\", \"\\u0627\\u0644\\u0642\\u0627\\u0646\\u0648\\u0646\", \"\\u0627\\u0644\\u0642\\u0631\\u0627\\u0621\\u0629\", \"\\u0627\\u0644\\u0643\\u0627\\u062a\\u0628\", \"\\u0627\\u0644\\u0643\\u0627\\u062a\\u0628\", \"\\u0627\\u0644\\u0643\\u0628\\u0631\\u0649\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u0643\\u062a\\u0627\\u0628\", \"\\u0627\\u0644\\u0643\\u062a\\u0628\", \"\\u0627\\u0644\\u0643\\u062a\\u0628\", \"\\u0627\\u0644\\u0643\\u062a\\u0628\", \"\\u0627\\u0644\\u0643\\u062b\\u064a\\u0631\", \"\\u0627\\u0644\\u0643\\u062b\\u064a\\u0631\", \"\\u0627\\u0644\\u0643\\u062b\\u064a\\u0631\", \"\\u0627\\u0644\\u0644\\u0647\", \"\\u0627\\u0644\\u0644\\u0647\", \"\\u0627\\u0644\\u0644\\u0647\", \"\\u0627\\u0644\\u0645\\u0627\\u062f\\u064a\", \"\\u0627\\u0644\\u0645\\u0627\\u0644\", \"\\u0627\\u0644\\u0645\\u0628\\u0634\\u0631\\u064a\\u0646\", \"\\u0627\\u0644\\u0645\\u062c\\u0644\\u062f\\u0627\\u062a\", \"\\u0627\\u0644\\u0645\\u062d\\u0645\\u062f\\u064a\\u0629\\u061b\", \"\\u0627\\u0644\\u0645\\u0648\\u0644\\u062f\", \"\\u0627\\u0644\\u0646\\u0628\\u064a\\u060c\", \"\\u0627\\u0644\\u0646\\u0628\\u064a\\u061b\", \"\\u0627\\u0644\\u0646\\u062c\\u0627\\u062d\", \"\\u0627\\u0644\\u0646\\u0638\\u0631\", \"\\u0627\\u0644\\u0646\\u0641\\u0633\", \"\\u0627\\u0644\\u0646\\u0641\\u0633\", \"\\u0627\\u0644\\u0646\\u0641\\u0633\", \"\\u0627\\u0644\\u0648\\u062c\\u0648\\u062f\", \"\\u0627\\u0644\\u0648\\u0641\\u0627\\u0629\", \"\\u0627\\u0644\\u064a\\u0647\\u0648\\u062f\\u064a\\u0629\", \"\\u0627\\u0646\\u0641\\u0639\\u0627\\u0644\\u0627\\u062a\", \"\\u0628\\u0627\\u0644\\u0621\\u0633\\u0627\\u0646\\u064a\\u062f\", \"\\u0628\\u0627\\u0644\\u062f\\u064a\\u0646\", \"\\u0628\\u0627\\u0644\\u0633\\u064a\\u0631\\u0629\", \"\\u0628\\u0627\\u0644\\u0646\\u0633\\u0628\\u0629\", \"\\u0628\\u0627\\u0644\\u0646\\u0633\\u0628\\u0629\", \"\\u0628\\u062a\\u0641\\u0627\\u0635\\u064a\\u0644\", \"\\u0628\\u062d\\u0631\\u0648\\u0641\", \"\\u0628\\u062d\\u0633\\u0646\", \"\\u0628\\u062d\\u0644\\u064a\", \"\\u0628\\u0631\\u062c\\u0627\\u0644\", \"\\u0628\\u0631\\u064a\\u0634\\u0629\", \"\\u0628\\u0634\\u0643\\u0644\", \"\\u0628\\u064a\\u0627\\u0646\\u0627\\u062a\", \"\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u062a\\u0627\\u0631\\u064a\\u062e\", \"\\u062a\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u062a\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u062a\\u0636\\u064a\\u0621\", \"\\u062a\\u0639\\u062f\", \"\\u062a\\u0639\\u062f\", \"\\u062a\\u0641\\u0627\\u0635\\u064a\", \"\\u062a\\u0641\\u062a\\u0631\", \"\\u062a\\u0643\\u0646\", \"\\u062a\\u0643\\u0646\", \"\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u062a\\u0646\\u0641\\u0630\", \"\\u062a\\u0648\\u0644\\u0633\\u062a\\u0648\\u064a\", \"\\u062c\\u0645\\u0639\\u064a\\u0627\\u062a\", \"\\u062d\\u0633\\u064a\\u0646\", \"\\u062d\\u0633\\u064a\\u0646\", \"\\u062d\\u0648\\u0627\\u062f\\u062b\\u0647\", \"\\u062d\\u0648\\u0644\", \"\\u062d\\u0648\\u0644\", \"\\u062d\\u0648\\u0644\", \"\\u062d\\u0648\\u0644\", \"\\u062d\\u064a\\u0627\\u062a\\u0647\", \"\\u062d\\u064a\\u0627\\u062a\\u0647\", \"\\u062e\\u0644\\u0627\\u0644\", \"\\u062e\\u0644\\u0627\\u0644\", \"\\u062e\\u0644\\u0627\\u0644\", \"\\u062e\\u0644\\u0627\\u0644\", \"\\u062e\\u0644\\u0648\\u062f\", \"\\u062f\\u062e\\u0648\\u0644\", \"\\u062f\\u0631\\u0627\\u0633\\u0629\", \"\\u062f\\u0631\\u062c\\u0629\", \"\\u062f\\u0641\\u0627\\u0639\\u0627\", \"\\u062f\\u0644\\u064a\\u0644\\u0627\", \"\\u062f\\u064a\\u0643\\u0627\\u0631\\u062a\", \"\\u0630\\u0643\\u0631\\u062a\", \"\\u0630\\u0643\\u0631\\u062a\", \"\\u0631\\u062d\\u0644\\u0629\", \"\\u0631\\u0648\\u0633\\u0648\", \"\\u0633\\u0637\\u0631\\u0648\\u0627\", \"\\u0633\\u0639\\u0627\\u062f\\u0629\", \"\\u0634\\u062a\\u0649\", \"\\u0634\\u062e\\u0635\", \"\\u0634\\u062e\\u0635\", \"\\u0634\\u062e\\u0635\", \"\\u0634\\u0645\\u0633\", \"\\u0634\\u0645\\u0633\", \"\\u0634\\u0645\\u0633\\u0627\", \"\\u0634\\u0647\\u0631\\u0629\", \"\\u0634\\u064a\\u0621\", \"\\u0634\\u064a\\u0621\", \"\\u0635\\u0627\\u062f\\u0642\", \"\\u0635\\u062d\\u0627\\u0628\\u0629\", \"\\u0635\\u0644\\u0627\\u062d\\u0647\\u0645\", \"\\u0635\\u0648\\u0631\\u0648\\u0627\", \"\\u0639\\u0627\\u0644\\u0645\", \"\\u0639\\u0627\\u0644\\u0645\", \"\\u0639\\u0627\\u0644\\u0645\", \"\\u0639\\u0627\\u0645\", \"\\u0639\\u0627\\u0645\", \"\\u0639\\u0627\\u0645\", \"\\u0639\\u0627\\u0645\", \"\\u0639\\u0635\\u0631\", \"\\u0639\\u0635\\u0631\", \"\\u0639\\u0638\\u0627\\u0645\", \"\\u0639\\u0644\\u064a\\u0647\\u0627\", \"\\u0639\\u0644\\u064a\\u0647\\u0627\", \"\\u0639\\u0644\\u064a\\u0647\\u0627\", \"\\u0639\\u0645\\u0631\", \"\\u0639\\u0645\\u0631\", \"\\u0639\\u0646\\u062f\\u0645\\u0627\", \"\\u0639\\u0646\\u062f\\u0645\\u0627\", \"\\u0639\\u064a\\u062f\", \"\\u0641\\u0621\\u0641\\u0631\\u062f\", \"\\u0641\\u0628\\u0639\\u062f\", \"\\u0641\\u062a\\u062a\\u062f\\u0627\\u062e\\u0644\", \"\\u0641\\u062d\\u0642\", \"\\u0641\\u0642\\u062f\", \"\\u0641\\u0642\\u062f\", \"\\u0641\\u0644\\u0633\\u0637\\u064a\\u0646\", \"\\u0642\\u0627\\u0632\\u0627\\u0646\\u060c\", \"\\u0642\\u062f\\u064a\\u0645\\u0627\", \"\\u0642\\u0645\\u0631\\u0627\", \"\\u0643\\u0627\\u0646\\u062a\", \"\\u0643\\u0627\\u0646\\u062a\", \"\\u0643\\u0627\\u0646\\u062a\", \"\\u0643\\u0628\\u0627\\u0631\", \"\\u0643\\u0628\\u0627\\u0631\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0643\\u062a\\u0627\\u0628\", \"\\u0643\\u062a\\u0627\\u0628\\u0647\", \"\\u0643\\u062a\\u0627\\u0628\\u0647\", \"\\u0643\\u062a\\u0627\\u0628\\u0647\", \"\\u0643\\u062a\\u0627\\u0628\\u0647\", \"\\u0643\\u062a\\u0628\", \"\\u0643\\u062a\\u0628\", \"\\u0643\\u062b\\u064a\\u0631\\u0629\", \"\\u0644\\u062d\\u0642\\u0627\", \"\\u0644\\u062e\\u062f\\u0645\\u0629\", \"\\u0644\\u0643\\u0644\", \"\\u0644\\u0643\\u0644\", \"\\u0644\\u0643\\u0644\", \"\\u0644\\u0643\\u0644\", \"\\u0644\\u0644\\u0639\\u0642\\u0644\", \"\\u0644\\u0644\\u0646\\u0627\\u0633\\u060c\", \"\\u0644\\u0645\\u062d\\u0645\\u062f\", \"\\u0644\\u064a\\u0633\\u0645\\u062d\", \"\\u0644\\u064a\\u0644\\u0645\", \"\\u0645\\u0628\\u062d\\u062b\", \"\\u0645\\u062d\\u0645\\u062f\", \"\\u0645\\u062d\\u0645\\u062f\", \"\\u0645\\u062d\\u0645\\u062f\", \"\\u0645\\u062d\\u0645\\u062f\", \"\\u0645\\u0635\\u0631\", \"\\u0645\\u0635\\u0631\", \"\\u0645\\u0635\\u0631\", \"\\u0645\\u0639\\u0627\\u0646\\u064a\\u0647\", \"\\u0645\\u0639\\u0631\\u0641\\u0629\", \"\\u0645\\u0639\\u0632\\u0632\\u0629\", \"\\u0645\\u0648\\u0627\\u062c\\u0647\\u0629\", \"\\u0645\\u0648\\u0627\\u062c\\u0647\\u0629\", \"\\u0645\\u0648\\u0636\\u0648\\u0639\\u0627\\u062a\", \"\\u0645\\u064a\\u0644\\u0627\\u062f\", \"\\u0646\\u062a\\u062d\\u062f\\u062b\", \"\\u0646\\u0634\\u0621\\u062a\\u0647\", \"\\u0646\\u0634\\u0621\\u062a\\u0647\", \"\\u0646\\u0648\\u0631\", \"\\u0647\\u0621\\u0644\\u0627\\u0621\", \"\\u0647\\u064a\\u0643\\u0644\\u060c\", \"\\u0648\\u0621\\u0631\\u0627\\u062f\", \"\\u0648\\u0621\\u0635\\u0631\\u0627\\u0631\", \"\\u0648\\u0621\\u0646\\u062a\", \"\\u0648\\u0621\\u0646\\u062a\", \"\\u0648\\u0627\\u0644\\u0621\\u0631\\u0627\\u0636\\u064a\", \"\\u0648\\u0627\\u0644\\u0621\\u0647\\u0648\\u0627\\u0621\", \"\\u0648\\u0627\\u0644\\u062a\\u0646\\u0648\\u064a\\u0631\", \"\\u0648\\u0627\\u0644\\u062e\\u0644\\u064a\\u0641\\u0629\", \"\\u0648\\u0627\\u0644\\u062f\\u0639\\u0627\\u064a\\u0629\", \"\\u0648\\u0627\\u0644\\u0639\\u0648\\u0627\\u0637\\u0641\", \"\\u0648\\u0627\\u0644\\u0646\\u0628\\u064a\", \"\\u0648\\u062a\\u0642\\u0644\\u0644\", \"\\u0648\\u062d\\u062f\\u064a\\u062b\\u0627\", \"\\u0648\\u0633\\u0644\\u0645\", \"\\u0648\\u0633\\u0644\\u0645\\u060c\", \"\\u0648\\u0642\\u062f\", \"\\u0648\\u0642\\u062f\", \"\\u0648\\u0642\\u062f\", \"\\u0648\\u0645\\u0639\\u0644\\u0645\\u0647\", \"\\u0648\\u0645\\u063a\\u0631\\u0642\\u0629\", \"\\u0648\\u0646\\u0634\\u0621\\u0629\", \"\\u0648\\u0646\\u0641\\u0639\\u0647\\u0645\", \"\\u0648\\u0647\\u064a\", \"\\u0648\\u0647\\u064a\", \"\\u0648\\u0647\\u064a\", \"\\u0648\\u0647\\u064a\", \"\\u0648\\u064a\\u0632\\u064a\\u0646\", \"\\u0648\\u064a\\u0633\\u062e\\u0631\\u0647\\u0627\", \"\\u0648\\u064a\\u0641\\u0633\\u0631\", \"\\u0648\\u064a\\u0644\\u0648\\u0646\\u0647\", \"\\u064a\\u0628\\u0642\\u0649\", \"\\u064a\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u064a\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u064a\\u062a\\u0646\\u0627\\u0648\\u0644\", \"\\u064a\\u062d\\u0627\\u0648\\u0644\", \"\\u064a\\u062d\\u0627\\u0648\\u0644\", \"\\u064a\\u062d\\u0644\\u0644\", \"\\u064a\\u062f\\u0631\\u064a\", \"\\u064a\\u0631\\u0633\\u0645\", \"\\u064a\\u0631\\u064a\\u062f\", \"\\u064a\\u0631\\u064a\\u062f\", \"\\u064a\\u0632\\u062e\\u0631\", \"\\u064a\\u0633\\u064a\\u0637\\u0631\", \"\\u064a\\u0634\\u0639\", \"\\u064a\\u0639\\u062f\", \"\\u064a\\u0639\\u062f\", \"\\u064a\\u0639\\u062f\", \"\\u064a\\u0639\\u062f\", \"\\u064a\\u0639\\u0644\\u0645\", \"\\u064a\\u0642\\u0631\\u0621\\u0647\", \"\\u064a\\u0643\\u0648\\u0646\", \"\\u064a\\u0643\\u0648\\u0646\", \"\\u064a\\u0643\\u0648\\u0646\", \"\\u064a\\u0645\\u0643\\u0646\", \"\\u064a\\u0645\\u0643\\u0646\", \"\\u064a\\u0645\\u0643\\u0646\", \"\\u064a\\u0646\\u0632\\u0644\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 3, 4, 2, 5]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el26351404108926205601942919776\", ldavis_el26351404108926205601942919776_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el26351404108926205601942919776\", ldavis_el26351404108926205601942919776_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el26351404108926205601942919776\", ldavis_el26351404108926205601942919776_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def get_topic_distribution(lda_model, bow, num_topics):\n",
        "    topic_dist = lda_model.get_document_topics(bow, minimum_probability=0)\n",
        "    return [prob for _, prob in sorted(topic_dist, key=lambda x: x[0])]\n",
        "\n",
        "topic_vectors = [get_topic_distribution(lda_model, doc, num_topics=5) for doc in corpus]\n",
        "X = np.array(topic_vectors)"
      ],
      "metadata": {
        "id": "Oz0YwQv-cK-w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df['Author']  # أو df['Rating'].astype(int)"
      ],
      "metadata": {
        "id": "UsRKWhmCclo5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olUS8KBTcoyr",
        "outputId": "de303147-0a8a-4bfc-ecde-53c7592118ed"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "           أحمد خالد توفيق       1.00      1.00      1.00         1\n",
            "                 أحمد عيسى       1.00      1.00      1.00         1\n",
            "                أسامة حمدي       1.00      1.00      1.00         1\n",
            "    أسامة زيد وهبة الصيادي       1.00      1.00      1.00         2\n",
            "              ألان م. ويبر       1.00      1.00      1.00         1\n",
            "                   ألن ديب       1.00      1.00      1.00         1\n",
            "           أمنية محمد لطفي       1.00      1.00      1.00         1\n",
            "              أنطونان أرتو       1.00      1.00      1.00         1\n",
            "                 أوسم وصفي       1.00      1.00      1.00         2\n",
            "إبراهيم عبد القادر المازني       1.00      1.00      1.00         1\n",
            "                إدورد برجر       1.00      1.00      1.00         1\n",
            "              إيهاب حمارنة       1.00      1.00      1.00         1\n",
            "              ا.س. رابوبرت       0.00      0.00      0.00         0\n",
            "               باولو كويلو       0.00      0.00      0.00         0\n",
            "           بشري عبد المؤمن       1.00      1.00      1.00         1\n",
            "                  بلال فضل       0.00      0.00      0.00         2\n",
            "                  بول آردن       1.00      1.00      1.00         1\n",
            "          جبران خليل جبران       1.00      1.00      1.00         2\n",
            "               جو ديسبينزا       0.00      0.00      0.00         0\n",
            "           جوزبه كاتوتسيلا       1.00      1.00      1.00         1\n",
            "           جون سي. ماكسويل       1.00      1.00      1.00         1\n",
            "              حاتم الكاملي       1.00      1.00      1.00         1\n",
            "                 حبيب زيات       1.00      1.00      1.00         1\n",
            "             د. جودي ويليس       1.00      1.00      1.00         1\n",
            "             دانتي ألغييري       1.00      1.00      1.00         1\n",
            "               دانيال بناك       1.00      1.00      1.00         1\n",
            "                دريني خشبة       1.00      1.00      1.00         1\n",
            "               ديل كارنيجي       0.00      0.00      0.00         2\n",
            "                رضوى عاشور       1.00      1.00      1.00         1\n",
            "                 رنيه خوام       0.00      0.00      0.00         0\n",
            "              رينيه ديكارت       1.00      1.00      1.00         1\n",
            "              زكي محمد حسن       1.00      1.00      1.00         1\n",
            "           زياد عبد التواب       1.00      1.00      1.00         1\n",
            "                سلامة موسى       1.00      1.00      1.00         3\n",
            "               عائض القرني       1.00      1.00      1.00         2\n",
            "         عباس محمود العقاد       1.00      1.00      1.00         3\n",
            "                عثمان موسى       1.00      1.00      1.00         1\n",
            "                  عمر جوبا       1.00      1.00      1.00         1\n",
            "                  عوض محمد       1.00      1.00      1.00         1\n",
            "            غاري فاينرتشاك       1.00      1.00      1.00         1\n",
            "              غوستاف لوبون       1.00      1.00      1.00         1\n",
            "             فريدريك نيتشه       1.00      1.00      1.00         1\n",
            "          فهد عامر الأحمدي       1.00      1.00      1.00         1\n",
            "               فيليب كوتلر       1.00      1.00      1.00         1\n",
            "               فيليبا بيري       1.00      1.00      1.00         1\n",
            "               كامل كيلاني       1.00      1.00      1.00         4\n",
            "                 لانس دودز       0.00      0.00      0.00         2\n",
            "                 لبنى الحو       0.00      0.00      0.00         0\n",
            "               ليو تولستوي       0.33      1.00      0.50         1\n",
            "               مارك مانسون       0.00      0.00      0.00         2\n",
            "            محمد أبو الغيط       0.00      0.00      0.00         2\n",
            "             محمد الشيباني       1.00      1.00      1.00         1\n",
            "             محمد حسام خضر       1.00      1.00      1.00         1\n",
            "            محمد حسين هيكل       1.00      1.00      1.00         1\n",
            "       محمد عبدالله الفريح       1.00      1.00      1.00         1\n",
            "                محمد غنايم       1.00      1.00      1.00         1\n",
            "        محمد قاسم عبد الله       1.00      1.00      1.00         1\n",
            "             مريد البرغوثي       1.00      1.00      1.00         1\n",
            "              مصطفى النشار       1.00      1.00      1.00         1\n",
            "        مصطفى صادق الرافعي       1.00      1.00      1.00         2\n",
            "      مصطفى لطفي المنفلوطي       1.00      1.00      1.00         2\n",
            "               ممدوح عدوان       1.00      1.00      1.00         1\n",
            "               منى المرشود       0.00      0.00      0.00         2\n",
            "        مي مجدي عبد الحكيم       1.00      1.00      1.00         1\n",
            "                نجيب محفوظ       1.00      1.00      1.00         1\n",
            "                 نجيب نصار       1.00      1.00      1.00         2\n",
            "         نيل ديغراس تايسون       1.00      1.00      1.00         1\n",
            "              هارييت جريفي       1.00      1.00      1.00         1\n",
            "                   هوميروس       1.00      1.00      1.00         1\n",
            "     وائل عبد اللطيف الفضل       1.00      1.00      1.00         1\n",
            "                 ياسر ثابت       1.00      1.00      1.00         1\n",
            "               يوسف الحسني       1.00      1.00      1.00         1\n",
            "                  يوسف كرم       1.00      1.00      1.00         1\n",
            "\n",
            "                  accuracy                           0.86        88\n",
            "                 macro avg       0.84      0.85      0.84        88\n",
            "              weighted avg       0.86      0.86      0.86        88\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# بناء القاموس والكوربوس\n",
        "dictionary = corpora.Dictionary(processed_descriptions)\n",
        "corpus = [dictionary.doc2bow(text) for text in processed_descriptions]\n",
        "\n",
        "# تدريب نموذج LDA\n",
        "lda = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10, random_state=42)\n",
        "\n",
        "# تحويل كل وصف إلى تمثيل مواضيع\n",
        "def get_topic_vector(bow):\n",
        "    topics = lda.get_document_topics(bow, minimum_probability=0)\n",
        "    return [prob for _, prob in sorted(topics, key=lambda x: x[0])]\n",
        "\n",
        "X = np.array([get_topic_vector(bow) for bow in corpus])\n",
        "y = df['Author']"
      ],
      "metadata": {
        "id": "L6s_LmZ1dh6Z"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cjsbz-PlctJB",
        "outputId": "5bab9fdf-93f4-4580-fb81-f9265506b7c2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            precision    recall  f1-score   support\n",
            "\n",
            "           أحمد خالد توفيق       1.00      1.00      1.00         1\n",
            "                 أحمد عيسى       1.00      1.00      1.00         1\n",
            "                أسامة حمدي       1.00      1.00      1.00         1\n",
            "    أسامة زيد وهبة الصيادي       1.00      1.00      1.00         2\n",
            "              ألان م. ويبر       1.00      1.00      1.00         1\n",
            "                   ألن ديب       1.00      1.00      1.00         1\n",
            "           أمنية محمد لطفي       1.00      1.00      1.00         1\n",
            "              أنطونان أرتو       1.00      1.00      1.00         1\n",
            "                 أوسم وصفي       1.00      1.00      1.00         2\n",
            "إبراهيم عبد القادر المازني       1.00      1.00      1.00         1\n",
            "                إدورد برجر       1.00      1.00      1.00         1\n",
            "              إيهاب حمارنة       1.00      1.00      1.00         1\n",
            "              ا.س. رابوبرت       0.00      0.00      0.00         0\n",
            "               باولو كويلو       0.00      0.00      0.00         0\n",
            "           بشري عبد المؤمن       1.00      1.00      1.00         1\n",
            "                  بلال فضل       0.00      0.00      0.00         2\n",
            "                  بول آردن       1.00      1.00      1.00         1\n",
            "          جبران خليل جبران       1.00      1.00      1.00         2\n",
            "               جو ديسبينزا       0.00      0.00      0.00         0\n",
            "           جوزبه كاتوتسيلا       1.00      1.00      1.00         1\n",
            "           جون سي. ماكسويل       1.00      1.00      1.00         1\n",
            "              حاتم الكاملي       1.00      1.00      1.00         1\n",
            "                 حبيب زيات       1.00      1.00      1.00         1\n",
            "             د. جودي ويليس       1.00      1.00      1.00         1\n",
            "             دانتي ألغييري       1.00      1.00      1.00         1\n",
            "               دانيال بناك       1.00      1.00      1.00         1\n",
            "                دريني خشبة       1.00      1.00      1.00         1\n",
            "               ديل كارنيجي       0.00      0.00      0.00         2\n",
            "                رضوى عاشور       1.00      1.00      1.00         1\n",
            "                 رنيه خوام       0.00      0.00      0.00         0\n",
            "              رينيه ديكارت       1.00      1.00      1.00         1\n",
            "              زكي محمد حسن       1.00      1.00      1.00         1\n",
            "           زياد عبد التواب       1.00      1.00      1.00         1\n",
            "                سلامة موسى       1.00      1.00      1.00         3\n",
            "               عائض القرني       1.00      1.00      1.00         2\n",
            "         عباس محمود العقاد       1.00      1.00      1.00         3\n",
            "                عثمان موسى       1.00      1.00      1.00         1\n",
            "                  عمر جوبا       1.00      1.00      1.00         1\n",
            "                  عوض محمد       1.00      1.00      1.00         1\n",
            "            غاري فاينرتشاك       1.00      1.00      1.00         1\n",
            "              غوستاف لوبون       1.00      1.00      1.00         1\n",
            "             فريدريك نيتشه       1.00      1.00      1.00         1\n",
            "          فهد عامر الأحمدي       1.00      1.00      1.00         1\n",
            "               فيليب كوتلر       1.00      1.00      1.00         1\n",
            "               فيليبا بيري       1.00      1.00      1.00         1\n",
            "               كامل كيلاني       1.00      1.00      1.00         4\n",
            "                 لانس دودز       0.00      0.00      0.00         2\n",
            "                 لبنى الحو       0.00      0.00      0.00         0\n",
            "               ليو تولستوي       0.33      1.00      0.50         1\n",
            "               مارك مانسون       0.00      0.00      0.00         2\n",
            "            محمد أبو الغيط       0.00      0.00      0.00         2\n",
            "             محمد الشيباني       1.00      1.00      1.00         1\n",
            "             محمد حسام خضر       1.00      1.00      1.00         1\n",
            "            محمد حسين هيكل       1.00      1.00      1.00         1\n",
            "       محمد عبدالله الفريح       1.00      1.00      1.00         1\n",
            "                محمد غنايم       1.00      1.00      1.00         1\n",
            "        محمد قاسم عبد الله       1.00      1.00      1.00         1\n",
            "             مريد البرغوثي       1.00      1.00      1.00         1\n",
            "              مصطفى النشار       1.00      1.00      1.00         1\n",
            "        مصطفى صادق الرافعي       1.00      1.00      1.00         2\n",
            "      مصطفى لطفي المنفلوطي       1.00      1.00      1.00         2\n",
            "               ممدوح عدوان       1.00      1.00      1.00         1\n",
            "               منى المرشود       0.00      0.00      0.00         2\n",
            "        مي مجدي عبد الحكيم       1.00      1.00      1.00         1\n",
            "                نجيب محفوظ       1.00      1.00      1.00         1\n",
            "                 نجيب نصار       1.00      1.00      1.00         2\n",
            "         نيل ديغراس تايسون       1.00      1.00      1.00         1\n",
            "              هارييت جريفي       1.00      1.00      1.00         1\n",
            "                   هوميروس       1.00      1.00      1.00         1\n",
            "     وائل عبد اللطيف الفضل       1.00      1.00      1.00         1\n",
            "                 ياسر ثابت       1.00      1.00      1.00         1\n",
            "               يوسف الحسني       1.00      1.00      1.00         1\n",
            "                  يوسف كرم       1.00      1.00      1.00         1\n",
            "\n",
            "                  accuracy                           0.86        88\n",
            "                 macro avg       0.84      0.85      0.84        88\n",
            "              weighted avg       0.86      0.86      0.86        88\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_new_description(text):\n",
        "    tokens = preprocess(text)\n",
        "    bow = dictionary.doc2bow(tokens)\n",
        "    topic_vector = get_topic_vector(bow)\n",
        "    prediction = clf.predict([topic_vector])[0]\n",
        "    return prediction\n",
        "\n",
        "new_desc = \"رواية تتحدث عن الحب والحرب في زمن مضطرب، ومشاعر امرأة تعيش صراعًا داخليًا...\"\n",
        "author_prediction = predict_new_description(new_desc)\n",
        "print(\"المؤلف المتوقع:\", author_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYTq_owldDXk",
        "outputId": "0b1a0441-fed3-48c1-ea2a-938b0804f05d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "المؤلف المتوقع: أدهم شرقاوي\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from pyarabic.araby import strip_tashkeel, strip_diacritics, normalize_hamza\n",
        "from gensim import corpora\n",
        "from gensim.models import LdaModel\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import joblib\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# تحميل كلمات الوقف\n",
        "nltk.download('stopwords')\n",
        "arabic_stopwords = set(stopwords.words(\"arabic\"))\n",
        "# تحويل الفئات النصية إلى أرقام باستخدام LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(df['RatingClass'])  # الآن y ستكون أرقامًا: 0، 1، 2\n",
        "\n",
        "\n",
        "df = df.dropna(subset=[\"Description\", \"Rating\"])  # نستخدم Rating هنا\n",
        "\n",
        "# تصنيف التقييمات إلى فئات (مثلاً: منخفض، متوسط، عالي)\n",
        "def classify_rating(r):\n",
        "    if r < 3.5:\n",
        "        return \"منخفض\"\n",
        "    elif r < 4.25:\n",
        "        return \"متوسط\"\n",
        "    else:\n",
        "        return \"عالي\"\n",
        "\n",
        "df['RatingClass'] = df['Rating'].apply(classify_rating)\n",
        "\n",
        "# المعالجة المسبقة للنصوص\n",
        "def preprocess(text):\n",
        "    text = strip_diacritics(strip_tashkeel(normalize_hamza(text)))\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
        "    tokens = text.split()\n",
        "    return [t for t in tokens if t not in arabic_stopwords and len(t) > 2]\n",
        "\n",
        "texts = [preprocess(desc) for desc in df['Description']]\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# تدريب LDA\n",
        "lda = LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10, random_state=42)\n",
        "\n",
        "# تحويل كل وصف إلى توزيع مواضيع\n",
        "# حويل كل وصف إلى تمثيل رقمي للمواضيع\n",
        "# كل كتاب يتحول إلى 5 أرقام تمثل احتمالية انتمائه لكل موضوع:\n",
        "def get_topic_vector(bow):\n",
        "    topics = lda.get_document_topics(bow, minimum_probability=0)\n",
        "    return [prob for _, prob in sorted(topics, key=lambda x: x[0])]\n",
        "\n",
        "X = np.array([get_topic_vector(bow) for bow in corpus])\n",
        "y = y_encoded\n",
        "\n",
        "# تدريب المصنف باستخدام XGBoost\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "xgb_clf = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
        "xgb_clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = xgb_clf.predict(X_test)\n",
        "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
        "y_test_labels = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "print(classification_report(y_test_labels, y_pred_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPr1WhVZdMbs",
        "outputId": "b78d144a-fb47-416b-e337-62e803d9229b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        عالي       0.90      0.88      0.89        49\n",
            "       متوسط       0.82      0.86      0.84        37\n",
            "       منخفض       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.86        88\n",
            "   macro avg       0.91      0.75      0.80        88\n",
            "weighted avg       0.87      0.86      0.86        88\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [23:15:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_rating_class(desc):\n",
        "    tokens = preprocess(desc)\n",
        "    bow = dictionary.doc2bow(tokens)\n",
        "    topic_vec = get_topic_vector(bow)\n",
        "    pred_num = xgb_clf.predict([topic_vec])[0]\n",
        "    pred_label = label_encoder.inverse_transform([pred_num])[0]\n",
        "    return pred_label\n",
        "\n",
        "new_desc = \"رواية تتحدث عن الحب والحرب في زمن مضطرب، ومشاعر امرأة تعيش صراعًا داخليًا...\"\n",
        "author_prediction = predict_new_description(new_desc)\n",
        "print(\"المؤلف المتوقع:\", author_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2P0ptqheIAX",
        "outputId": "1e693ce0-5678-4d72-8c18-9de76d562bde"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "المؤلف المتوقع: أدهم شرقاوي\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# تخزين المصنف\n",
        "joblib.dump(xgb_clf, \"xgb_rating_classifier.pkl\")\n",
        "\n",
        "# تخزين LDA والقاموس\n",
        "lda.save(\"lda_model.model\")\n",
        "dictionary.save(\"lda_dictionary.dict\")\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J3uEnKTf7X4",
        "outputId": "f0cc10d5-753a-4c99-833d-e9382ce969e7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# تحميل النماذج المحفوظة\n",
        "xgb_clf = joblib.load(\"xgb_rating_classifier.pkl\")\n",
        "lda = LdaModel.load(\"lda_model.model\")\n",
        "dictionary = corpora.Dictionary.load(\"lda_dictionary.dict\")\n",
        "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
        "\n",
        "def predict_rating_class(desc):\n",
        "    tokens = preprocess(desc)\n",
        "    bow = dictionary.doc2bow(tokens)\n",
        "    topic_vec = get_topic_vector(bow)\n",
        "    pred_num = xgb_clf.predict([topic_vec])[0]\n",
        "    pred_label = label_encoder.inverse_transform([pred_num])[0]\n",
        "    return pred_label\n",
        "\n",
        "# تجربة:\n",
        "text = \"رواية روحانية تبحث عن الذات وتناقش الحب والخسارة في زمن الحرب\"\n",
        "print(\"تقييم متوقع:\", predict_rating_class(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhLcPlU6f8Dl",
        "outputId": "408ffb02-b044-4856-cda1-a6aee552842d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "تقييم متوقع: عالي\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# حفظ المصنف\n",
        "joblib.dump(xgb_clf, \"xgb_rating_classifier.pkl\")\n",
        "\n",
        "# حفظ LDA والقاموس\n",
        "lda.save(\"lda_model.model\")\n",
        "dictionary.save(\"lda_dictionary.dict\")\n",
        "joblib.dump(label_encoder, \"label_encoder.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox42gfLyf_9r",
        "outputId": "4a66b5c2-8fd9-4b3b-f46f-1c309062fbba"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SMXYl6TIgmrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}